{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemEval-2020 Task 12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piotrjaniszewski1/SemEval-2020-Task12/blob/master/SemEval_2020_Task_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkSswYeCqZUP",
        "colab_type": "text"
      },
      "source": [
        "# **Package installation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITbytJ9fJ00a",
        "colab_type": "code",
        "outputId": "f64d95d6-47b9-4fe3-9f4d-70bc4df2caad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Install necessary packages\n",
        "\n",
        "!pip install unidecode\n",
        "!pip install contractions\n",
        "!pip install wordsegment\n",
        "!pip install -U symspellpy\n",
        "!pip install emoji --upgrade\n",
        "!pip install -U imbalanced-learn"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.23)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
            "Requirement already satisfied: wordsegment in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already up-to-date: symspellpy in /usr/local/lib/python3.6/dist-packages (6.5.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.17.4)\n",
            "Requirement already up-to-date: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n",
            "Collecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/62/08c14224a7e242df2cef7b312d2ef821c3931ec9b015ff93bb52ec8a10a3/imbalanced_learn-0.5.0-py3-none-any.whl (173kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.21.3)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zXay3ngqjfk",
        "colab_type": "text"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP7i81J8twMn",
        "colab_type": "code",
        "outputId": "32309ad0-b21b-4f7d-9e45-23eb459e3e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# All imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from bs4 import BeautifulSoup\n",
        "import unidecode\n",
        "import contractions\n",
        "import gensim.downloader as api\n",
        "import re\n",
        "import wordsegment\n",
        "import pkg_resources\n",
        "from symspellpy.symspellpy import SymSpell, Verbosity\n",
        "import emoji\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "wordsegment.load()\n",
        "spell = SpellChecker()\n",
        "\n",
        "# Load SymSpell -> package for correcting misspellings\n",
        "sym_spell = SymSpell(2, 7)\n",
        "\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "bigram_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
        "\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mER1mPUtiaPl",
        "colab_type": "code",
        "outputId": "316cdcd5-dabe-48fa-ddf1-4dfec643d805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Import data\n",
        "training_examples_url = 'https://raw.githubusercontent.com/piotrjaniszewski1/SemEval-2020-Task12/master/data2019/olid-training-v1.0.tsv'\n",
        "training_dataset = pd.read_csv(training_examples_url, delimiter='\\t')\n",
        "print(training_dataset.head())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      id                                              tweet  ... subtask_b subtask_c\n",
            "0  86426  @USER She should ask a few native Americans wh...  ...       UNT       NaN\n",
            "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...  ...       TIN       IND\n",
            "2  16820  Amazon is investigating Chinese employees who ...  ...       NaN       NaN\n",
            "3  62688  @USER Someone should'veTaken\" this piece of sh...  ...       UNT       NaN\n",
            "4  43605  @USER @USER Obama wanted liberals &amp; illega...  ...       NaN       NaN\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73i5BO8TqoTE",
        "colab_type": "text"
      },
      "source": [
        "# **Training and validation sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xHoiMYYlJQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_examples, validation_examples = train_test_split(training_dataset, test_size=0.1)\n",
        "\n",
        "# prepare training examples\n",
        "training_examples_A = training_examples['tweet'][training_examples['subtask_a'].notnull()]\n",
        "training_examples_B = training_examples['tweet'][training_examples['subtask_b'].notnull()]\n",
        "training_examples_C = training_examples['tweet'][training_examples['subtask_c'].notnull()]\n",
        "\n",
        "# prepare validation examples\n",
        "validation_examples_A = validation_examples['tweet'][validation_examples['subtask_a'].notnull()]\n",
        "validation_examples_B = validation_examples['tweet'][validation_examples['subtask_b'].notnull()]\n",
        "validation_examples_C = validation_examples['tweet'][validation_examples['subtask_c'].notnull()]\n",
        "\n",
        "# prepare training labels\n",
        "training_labels_A = (training_examples['subtask_a'][training_examples['subtask_a'].notnull()] == 'OFF').astype(int)\n",
        "training_labels_B = (training_examples['subtask_b'][training_examples['subtask_b'].notnull()] == 'TIN').astype(int)\n",
        "c_mapping = {'IND': 0, 'GRP': 1, 'OTH': 2}\n",
        "training_labels_C = training_examples['subtask_c'][training_examples['subtask_c'].notnull()].replace(c_mapping)\n",
        "\n",
        "# prepare validation labels\n",
        "validation_labels_A = (validation_examples['subtask_a'][validation_examples['subtask_a'].notnull()] == 'OFF').astype(int)\n",
        "validation_labels_B = (validation_examples['subtask_b'][validation_examples['subtask_b'].notnull()] == 'TIN').astype(int)\n",
        "validation_labels_C = (validation_examples['subtask_c'][validation_examples['subtask_c'].notnull()]).replace(c_mapping)\n",
        "\n",
        "\n",
        "training_x = list(training_examples_A)\n",
        "validation_x = list(validation_examples_A)\n",
        "training_y = list(training_labels_A)\n",
        "validation_y = list(validation_labels_A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2bNpHc9qMpw",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAHp6jlH12sD",
        "colab_type": "code",
        "outputId": "c967661e-1d55-4338-dd08-284b9b541e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# normalization -> papers, complicated solutions\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# exclude negation words from spacy stopwords list\n",
        "deselect_stop_words = ['no', 'not', 'noone', 'none', 'lacks', 'lack', 'nor', 'never', 'neighter', 'hardly', 'nobody', 'nothing', 'lacking', 'nowhere']\n",
        "for w in deselect_stop_words:\n",
        "    nlp.vocab[w].is_stop = False\n",
        "\n",
        "\n",
        "# remove html tags if exist\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    stripped_text = soup.get_text(separator=' ')\n",
        "    return stripped_text\n",
        "\n",
        "\n",
        "# remove unnecessary whitespaces\n",
        "def remove_whitespace(text):\n",
        "    text = text.strip()\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "\n",
        "# remove accented chars (e.g. caffè -> caffe)\n",
        "def remove_accented_chars(text):\n",
        "    text = unidecode.unidecode(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# remove hashes and split words (e.g. '#fortTrump' -> 'fort trump')\n",
        "def split_hashtags(text):\n",
        "    splitted = text.split()\n",
        "    new_word_sequence = []\n",
        "\n",
        "    for chunk in splitted:\n",
        "        if chunk[0] == '#':\n",
        "            chunk = chunk[1:]\n",
        "            new_word_sequence.extend(wordsegment.segment(chunk))\n",
        "        else:\n",
        "            new_word_sequence.append(chunk)\n",
        "        \n",
        "    return ' '.join(tuple(new_word_sequence))\n",
        "\n",
        "\n",
        "def substitute_emojis(text):\n",
        "    demojized_text = emoji.demojize(text)\n",
        "    return re.compile('[_:]+').sub(' ', demojized_text)\n",
        "\n",
        "\n",
        "# all preprocessing executions\n",
        "def preprocess_basic(text):\n",
        "    text = strip_html_tags(text)\n",
        "    text = contractions.fix(text)\n",
        "    text = split_hashtags(text)\n",
        "    text = substitute_emojis(text)\n",
        "    text = remove_whitespace(text)\n",
        "    text = remove_accented_chars(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    clean_text = []\n",
        "    \n",
        "    for token in doc:\n",
        "        flag = True\n",
        "        edit = token.text\n",
        "\n",
        "        # remove punctuations\n",
        "        if token.pos_ == 'PUNCT' and flag == True and token.text != '@user': \n",
        "            flag = False\n",
        "       \n",
        "        # remove special characters\n",
        "        if token.pos_ == 'SYM' and flag == True: \n",
        "            flag = False\n",
        "        \n",
        "        # remove numbers\n",
        "        if (token.pos_ == 'NUM' or token.text.isnumeric()) and flag == True:\n",
        "            flag = False\n",
        "\n",
        "        # correct misspelings\n",
        "        if flag == True:\n",
        "            suggestions = sym_spell.lookup(edit, Verbosity.TOP, 2)\n",
        "            if len(suggestions) > 0:\n",
        "                edit = suggestions[0].term\n",
        "\n",
        "        # remove stop words\n",
        "        if token.is_stop and token.pos_ != 'NUM': \n",
        "            flag = False\n",
        "\n",
        "        # convert tokens to base form\n",
        "        elif token.lemma_ != '-PRON-' and flag == True:\n",
        "            edit = token.lemma_\n",
        "\n",
        "        # append tokens edited and not removed to list \n",
        "        if edit != '' and flag == True:\n",
        "            clean_text.append(edit)        \n",
        "    \n",
        "    return clean_text\n",
        "\n",
        "\n",
        "cleaned_x = [preprocess_basic(example) for example in training_x[0:30]]\n",
        "print(cleaned_x[0:30])\n",
        "print(training_x[0:30])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['@user', '@user', '@user', '@user', 'amazing', 'organizer', 'clap', 'hand', 'medium', 'dark', 'skin', 'tone'], ['mind', 'open', 'conservative', 'republican', 'maga', 'shadow', 'ban', 'america', 'trump', 'patriot', '@user', '@user', '@user', '@user', '@user', '@user', '@user', 'walk', 'away', 'walk', 'away', 'democrat', 'fake', 'news', '@user', '@user', '@user', '@user', '@user', '@user', 'url'], ['@user', 'disgusting', 'proof', 'property', 'home', 'ownership', 'myth', 'not', 'pay', 'taxis', 'rent', 'throw', 'land', 'need', 'permission', 'build', 'land'], ['@user', 'enemy', 'great', 'point', 'compromise', 'source', 'method', 'source', 'method', 'conservative', 'concerned', 'drain', 'swamp'], ['@user', 'loudly', 'cry', 'face', 'loudly', 'cry', 'face', 'loudly', 'cry', 'face', 'loudly', 'cry', 'face', 'terrible', 'ok', 'button'], ['@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', 'thank', 'allow', 'aboard', 'proudly', 'follow', 'maga', 'kag', 'patriot', 'united', 'state'], ['@user', 'know', 'not', 'real', 'republican', 'commit', 'party', 'need', 'leave', 'disgrace', 'republican', 'conservative', 'member', 'work', 'solution', 'not', 'constantly', 'diminish', 'potus', 'quit'], ['@user', 'not', 'like'], ['@user', 'not', 'know', 'slam', 'manifort', 'suck', 'not', 'know', 'worry', 'junior', 'kushner', 'not', 'mad', 'hell', 'know', 'not', 'fire', 'mueller', 'busy', 'puke', 'bathroom', 'understand', 'asset', 'seizure', 'thing'], ['@user', 'select', 'liberal', 'cheat', 'voter', 'change', 'mind', 'election', 'ms', 'alleslev'], ['@user', 'school', 'food', 'ass', 'anyway', 'face', 'tear', 'joy', 'face', 'tear', 'joy'], ['@user', 'obviously', 'not', 'boycott', '@user'], ['@user', '@user', '@user', 'deal', 'samrat', 'family', 'think', 'save', 'case', 'know', 'samrat', 'attract', 'girl', 'teju', 'geetha', 'complaint', 'come', 'take', 'care', 'sad', 'wife', 'kaushal', 'army', 'biggbosstelugu2'], ['@user', '@user', '@user', '@user', '@user', '@user', 'congratulation'], ['@user', '@user', '@user', 'awesome', 'tweet', 'bring', 'good', 'people', 'appreciate', 'thank', 'yesterday', 'live', 'update', 'live', 'coverage', 'news', 'story'], ['@user', '@user', '@user', 'today', 'happy', 'succeed', 'work', 'award', 'reward', 'effortless', 'try', 'wish', 'award', 'life', 'beginning', 'journey', 'lot', 'thing', 'achieve', 'congratulation', 'win', 'award', 'dear', '@user'], ['@user', '@user', 'go', 'eye'], ['@user', 'troll', 'antifa'], ['@user', 'go', 'op', 'asf', 'week', 'url'], ['@user', '@user', 'usa', 'ww2', 'soldier', 'antifa', 'anti', '-', 'fascist', 'kill'], ['@user', 'terrorist', 'antifa', 'farrakhan', 'hateful', 'racist', 'thug', 'blm', 'criminal', 'black', 'panther', 'group', 'no', 'place'], ['@user', 'course', 'not', 'obviously', 'complete', 'bs', 'want', 'delay', 'time', 'vote', 'come', 'w/', 'plant', 'accuser', 'suppose', 'victim', 'apparent', 'rape', 'liberal', 'come', 'look', 'like', 'lesbian', 'art', 'teacher', 'lol'], ['@user', '@user', 'total', 'mental', 'breakdown', '-', 'elect'], ['@user', '@user', '@user', 'right', 'convenient', 'time', 'possible', 'wrinkle', 'throw', 'conservative', 'dem', 'whine', 'cry', 'stomp', 'foot', 'throw', 'tantrum', 'rest', 'america', 'trust', 'definitely', 'not', 'lie', 'snake', 'deserve', 'nothing'], ['@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', '@user', 'right', 'conditioning', 'sort', 'result', 'denial', 'irrelevant', 'fact', 'welcome', 'cognitive', 'dissonance', 'disguise-', 'antifa', 'woman', 'facepalme', 'light', 'skin', 'tone'], ['@user', 'holy', 'shit', 'no', 'way'], ['@user', 'ok', 'hear', 'superman', 'thing', 'time', 'certainly', 'busy', 'excellent', 'opportunity', 'step', 'movie', 'cavill', 'step', 'url'], ['evil', 'url'], ['@user', 'child', 'retarded'], ['@user', 'not', 'face', 'tear', 'joy', 'face', 'tear', 'joy', 'face', 'tear', 'joy', 'face', 'tear', 'joy', 'face', 'tear', 'joy']]\n",
            "['@USER @USER @USER @USER You are an amazing organizer 👏🏾', 'Keep your mind open. #conservatives #republican #MAGA #Shadowbanning #AmericaFirst #Trump #Patriot @USER @USER @USER @USER @USER @USER @USER #WalkAway #WalkAwayFromDemocrats #FakeNews @USER @USER @USER @USER @USER @USER URL', \"@USER Disgusting. This is just more proof that property and home ownership is a MYTH...if you don't pay the taxes (RENT) you are thrown off YOUR LAND...you need PERMISSION to build on YOUR LAND.\", '@USER The enemy within seems greater at this point than compromising sources and methods. It’s the sources and methods we Conservatives are concerned about! #draintheswamp', '@USER 😭😭😭😭 he is terrible 🆗', '@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Thank you for allowing me aboard!  Proudly following all #MAGA #KAG Patriots 🇺🇸', '@USER I knew you weren’t a Real Republican committed to your party!!!! You need to leave. Get out now!! You are a disgrace to every republican/conservative member who work towards solutions and does not constantly diminish The POTUS!!! Quit already.', '@USER he is doing it to everyone he don’t like', '@USER He doesn’t know if he should slam Manifort or suck up to him. He doesn’t know if he should worry about Junior and Kushner or not. He is mad as hell but knows that he can’t just fire Mueller so he is busy puking in the bathroom now that he understands that asset seizure is a thing', '@USER You’ve been selected by Liberals! Are you cheating on your voters. You should have changed your mind before the election Ms. Alleslev', '@USER School food ass anyways😂😂', '@USER He obviously isn’t boycotting @USER', '@USER @USER @USER has a deal with samrat family i think to save him from the case. We know how samrat is attract for girls teju and geetha. Now when complaint came he is taking care. Sad for her wife #KaushalArmy #BiggBossTelugu2', '@USER @USER @USER @USER @USER @USER Congratulations!', \"@USER @USER @USER Awesome tweet. You bring out the best in people and you are appreciated. Thanks for yesterday's many live updates  and live coverage and that was just one news story!\", '@USER @USER @USER Today I am happy for you as you succeed in your work. The award you are rewarded is for you effortless trying. I wish many more awards in your life. It is the beginning of journey and lots of things are yet to achieve. Congratulation for winning this award dear @USER', '@USER @USER Or perhaps it’s because he is gone 👀', '@USER 4chan trolling Antifa again?', '@USER He is gonna be OP asf for the first few weeks URL', '@USER @USER Our  USA WW2 soldiers were all Antifa anti-fascists too. They killed them.', '@USER What?  All 12 of them?  What about the terrorists Antifa?  Farrakhan’s hateful and racist thugs?  BLM criminals?  Black Panthers?  Those groups have NO place either!', '@USER Of course they shouldnt cause its obviously complete bs. They just want it delayed and when its time for the vote again theyll come up w/ another plant accuser. And why does every supposed victim of apparent “rape” liberals come up with always look like a lesbian art teacher lol', '@USER @USER She’ll have a total mental breakdown when he is re-elected!!!!', '@USER @USER @USER Right now is the most convenient time for a possible\" wrinkle to thrown at Conservatives. Dems have whined and cried and stomp their feet and thrown tantrums until the rest of America that may have trusted them definitely dont now. Theyre lying snakes and they deserve nothing.\"', \"@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Right ... It's a conditioning of sorts resulting in denial... Irrelevant of the facts... THUS Welcomes Cognitive Dissonance in Disguise- ANTIFA 🤦🏻\\u200d♀️\", '@USER HOLY SHIT NO WAY', '@USER Ok - you hear about the superman\" thing all the time. And you are certainly busy, but, this could be an EXCELLENT opportunity to step in, in the movies for him as Cavill is steping down!:  URL', ':( She is very evil. URL', '@USER He is a child ~ a retarded one.', '@USER Don’t 😂😂😂😂😂']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4Gjm9OhOzug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove redundant @user tokens\n",
        "def remove_redundant_users(example):\n",
        "  user_count = 0\n",
        "  new_example = example[:]\n",
        "  for i, token in reversed(list(enumerate(example))):\n",
        "    if token == '@user':\n",
        "      user_count += 1\n",
        "      if user_count > 3:\n",
        "        new_example.pop(i)\n",
        "\n",
        "    else:\n",
        "      user_count = 0\n",
        "\n",
        "  return new_example\n",
        "\n",
        "reduced_users_x = [remove_redundant_users(example) for example in cleaned_x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sof2hmndqxQ-",
        "colab_type": "text"
      },
      "source": [
        "# **Class imbalance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMEzRiyEsxDV",
        "colab_type": "code",
        "outputId": "ca974b64-57fd-4bde-9a19-75f3c37338e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "#Depict class imbalance for the subtask A\n",
        "sns.set(font_scale=1.0)\n",
        "countplt=sns.countplot(x='subtask_a', data=training_dataset, palette ='hls')\n",
        "plt.show()\n",
        "\n",
        "print(training_dataset.groupby('subtask_a').count()['id'])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEMCAYAAAABLFv3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWeklEQVR4nO3da1BU9/3H8c/uUla8IggIUu81oWFS\n1K3W1NSGmGAVJc7EwSE143grWuqlrRGNAeIlLWhtvSUYk0YfVDOZThoDsaFNm9okWhvSqjWmNUVt\nVVAMFy+goLvbB477D/+Irvtjd1l5vx7F89vDfpfZ8OacZfdY3G63WwAAGLAGewAAQOgjJgAAY8QE\nAGCMmAAAjBETAIAxYgIAMEZMAADGwoI9QDDV1TXI5eJtNgDgDavVop49u9x0rUPHxOVyExMAaAOc\n5gIAGCMmAABjxAQAYIyYAACMERMAgDFiAgAwRkwAAMY69PtMgLtV956dZQ+zBXsMtDNN15y6UNfo\nl69NTIC7kD3Mpuy95cEeA+1M8QMOv31tTnMBAIwREwCAMWICADBGTAAAxogJAMAYMQEAGCMmAABj\nxAQAYIyYAACMERMAgDFiAgAwRkwAAMaICQDAGDEBABgLWEzeffddPfbYY8rIyNCkSZP0u9/9TpJ0\n/PhxZWZmKi0tTZmZmTpx4oRnH1/XAACBFZCYuN1uPfXUUyoqKtKuXbtUVFSkJUuWyOVyKT8/X1lZ\nWSorK1NWVpby8vI8+/m6BgAIrIAdmVitVl28eFGSdPHiRcXGxqqurk5HjhxRenq6JCk9PV1HjhxR\nbW2tampqfFoDAAReQK60aLFY9Itf/ELz5s1T586d1dDQoBdffFFVVVWKi4uTzXb98qI2m02xsbGq\nqqqS2+32aS0qKioQDwkA8DkBicm1a9e0ZcsWPf/88xo+fLg++ugjLVy4UEVFRYG4+1ZFR3cN6v0D\nQKDFxHTzy9cNSEw++eQTVVdXa/jw4ZKk4cOHKyIiQna7XWfPnpXT6ZTNZpPT6VR1dbXi4+Pldrt9\nWrsTNTWX5HK5/fGQgaDy1w8MhL5z5y76vK/Vamn1l/CAvGbSu3dvnTlzRseOHZMkVVRUqKamRv36\n9VNSUpJKS0slSaWlpUpKSlJUVJSio6N9WgMABJ7F7XYH5FfzN998U1u3bpXFYpEkzZ8/X2PHjlVF\nRYVyc3N14cIFde/eXYWFhRo4cKAk+bzmLY5McLeKiemm7L3lwR4D7UzxAw6/HZkELCbtETHB3YqY\n4Gb8GRPeAQ8AMEZMAADGiAkAwBgxAQAYIyYAAGPEBABgjJgAAIwREwCAMWICADBGTAAAxogJAMAY\nMQEAGCMmAABjxAQAYIyYAACMERMAgDFiAgAwRkwAAMaICQDAGDEBABgjJgAAY8QEAGCMmAAAjBET\nAIAxYgIAMEZMAADGiAkAwBgxAQAYIyYAAGPEBABgjJgAAIwREwCAMWICADBGTAAAxogJAMAYMQEA\nGCMmAABjxAQAYCxgMWlqalJ+fr4effRRTZw4Uc8884wk6fjx48rMzFRaWpoyMzN14sQJzz6+rgEA\nAitgMVmzZo3sdrvKyspUUlKiBQsWSJLy8/OVlZWlsrIyZWVlKS8vz7OPr2sAgMAKSEwaGhr0xhtv\naMGCBbJYLJKkXr16qaamRkeOHFF6erokKT09XUeOHFFtba3PawCAwAsLxJ2cPHlSkZGR2rRpk/bv\n368uXbpowYIF6tSpk+Li4mSz2SRJNptNsbGxqqqqktvt9mktKioqEA8JAPA5AYmJ0+nUyZMn9dWv\nflVLlizRwYMHlZ2drfXr1wfi7lsVHd01qPcPAIEWE9PNL183IDGJj49XWFiY57TU1772NfXs2VOd\nOnXS2bNn5XQ6ZbPZ5HQ6VV1drfj4eLndbp/W7kRNzSW5XG5/PGQgqPz1AwOh79y5iz7va7VaWv0l\nPCCvmURFRWnkyJH64IMPJF3/S6yamhr1799fSUlJKi0tlSSVlpYqKSlJUVFRio6O9mkNABB4Frfb\nHZBfzU+ePKlly5apvr5eYWFhWrhwocaMGaOKigrl5ubqwoUL6t69uwoLCzVw4EBJ8nnNWxyZ4G4V\nE9NN2XvLgz0G2pniBxx+OzIJWEzaI2KCuxUxwc34Mya8Ax4AYIyYAACMERMAgDFiAgAwRkwAAMaI\nCQDAGDEBABgjJgAAY8QEAGCMmAAAjBETAIAxYgIAMOZ1TF5++eWbbn/llVfabBgAQGjyOiabN2++\n6fYXXnihzYYBAISm215pcd++fZIkl8ulv/zlL/r8J9afOnVKXbp08d90AICQcNuYPP3005KkpqYm\nLVu2zLPdYrEoJiZGy5cv9990AICQcNuY/PGPf5QkPfXUUyoqKvL7QACA0HPbmNzw+ZC4XK4Wa1Yr\nfxQGAB2Z1zH5+OOPtWLFCv3rX/9SU1OTJMntdstiseiTTz7x24AAgPbP65jk5ubqoYce0nPPPadO\nnTr5cyYAQIjxOianT5/WokWLZLFY/DkPACAEef1ixyOPPKL333/fn7MAAEKU10cmTU1NysnJ0fDh\nw9WrV68Wa/yVFwB0bF7HZPDgwRo8eLA/ZwEAhCivY5KTk+PPOQAAIczrmNz4WJWbGTVqVJsMAwAI\nTV7H5MbHqtxQV1enq1evKi4uTn/4wx/afDAAQOjwOiY3PlblBqfTqRdeeIEPegQA+H5xLJvNpuzs\nbL300kttOQ8AIAQZfajWBx98wJsYAQDen+YaM2ZMi3BcvnxZzc3Nys/P98tgAIDQ4XVM1qxZ0+Lf\nERERGjBggLp27drmQwEAQovXMRkxYoSk6x8//9lnn6lXr14d+qPne3a3K8weHuwx0M5ca2pW3YWm\nYI8BBJzXMbl06ZJWrFih3bt369q1awoLC9OECRO0fPlydevWzZ8ztkth9nCVz88O9hhoZxwbiiUR\nE3Q8Xh9arFq1SpcvX1ZJSYkOHTqkkpISXb58WatWrfLnfACAEOD1kcl7772nd955RxEREZKkAQMG\n6Cc/+YkeeeQRvw0HAAgNXh+Z2O121dbWtthWV1en8HBeNwCAjs7rI5PHH39cM2bM0PTp05WQkKDK\nykpt27ZNU6ZM8ed8AIAQ4HVM5s6dq7i4OJWUlKi6ulqxsbGaNWvWHcdk06ZN2rhxo0pKSjRkyBAd\nOHBAeXl5ampqUp8+fbRmzRpFR0dLks9rAIDA8vo01+rVqzVgwABt27ZNu3fv1rZt2zRo0CCtXr3a\n6zv7+OOPdeDAAfXp00fS9T8zXrx4sfLy8lRWViaHw6G1a9carQEAAs/rmJSWlio5ObnFtuTkZJWW\nlnq1f3Nzs1asWKGCggLPtsOHD8tut8vhcEiSpk6dqrfffttoDQAQeF7HxGKxyOVytdjmdDq/sK01\n69ev16RJk5SYmOjZVlVVpYSEBM+/o6Ki5HK5VF9f7/MaACDwvH7NxOFwaP369Vq8eLGsVqtcLpc2\nbtzoOTq4lb///e86fPiwfvzjHxsN29aio/koGLS9mJiO9yZehA5/PT/v6OJY3/ve9zR69GglJCSo\nqqpKMTExKi4uvu2+H374oSoqKvTwww9Lks6cOaOZM2dq2rRpqqys9NyutrZWVqtVkZGRio+P92nt\nTtTUXJLL5b6jfW7gBwZac+7cxWCPwPMTrTJ5flqtllZ/Cfc6Jr1799ZvfvMbHTp0SFVVVYqPj9f9\n99/v1edzzZkzR3PmzPH8OzU1VcXFxRo8eLBee+01lZeXy+Fw6NVXX9W4ceMkXX895sqVK3e8BgAI\nPK9jIklWq1UpKSlKSUlpkzu3Wq0qKipSfn5+iz/xNVkDAASexe12+3ae5y5gepqLD3rE/+fYUNxu\nTnNl7y0P9hhoZ4ofcPjtNFfH/Qx5AECbISYAAGPEBABgjJgAAIwREwCAMWICADBGTAAAxogJAMAY\nMQEAGCMmAABjxAQAYIyYAACMERMAgDFiAgAwRkwAAMaICQDAGDEBABgjJgAAY8QEAGCMmAAAjBET\nAIAxYgIAMEZMAADGiAkAwBgxAQAYIyYAAGPEBABgjJgAAIwREwCAMWICADBGTAAAxogJAMAYMQEA\nGCMmAABjxAQAYIyYAACMERMAgDFiAgAwFpCY1NXVafbs2UpLS9PEiROVk5Oj2tpaSdKBAwc0adIk\npaWlacaMGaqpqfHs5+saACCwAhITi8WiWbNmqaysTCUlJfryl7+stWvXyuVyafHixcrLy1NZWZkc\nDofWrl0rST6vAQACLyAxiYyM1MiRIz3/TklJUWVlpQ4fPiy73S6HwyFJmjp1qt5++21J8nkNABB4\nYYG+Q5fLpZ07dyo1NVVVVVVKSEjwrEVFRcnlcqm+vt7ntcjISK9niY7u2jYPCvicmJhuwR4BaJW/\nnp8Bj8nKlSvVuXNnffe739Xvf//7QN99CzU1l+RyuX3alx8YaM25cxeDPQLPT7TK5PlptVpa/SU8\noDEpLCzUf/7zHxUXF8tqtSo+Pl6VlZWe9draWlmtVkVGRvq8BgAIvID9afC6det0+PBhbd68WeHh\n4ZKk5ORkXblyReXl5ZKkV199VePGjTNaAwAEXkCOTD799FNt2bJF/fv319SpUyVJiYmJ2rx5s4qK\nipSfn6+mpib16dNHa9askSRZrVaf1gAAgWdxu92+vWhwFzB9zaR8fnYbT4RQ59hQ3G5eM8neWx7s\nMdDOFD/g8NtrJrwDHgBgjJgAAIwREwCAMWICADBGTAAAxogJAMAYMQEAGCMmAABjxAQAYIyYAACM\nERMAgDFiAgAwRkwAAMaICQDAGDEBABgjJgAAY8QEAGCMmAAAjBETAIAxYgIAMEZMAADGiAkAwBgx\nAQAYIyYAAGPEBABgjJgAAIwREwCAMWICADBGTAAAxogJAMAYMQEAGCMmAABjxAQAYIyYAACMERMA\ngDFiAgAwRkwAAMaICQDAWEjH5Pjx48rMzFRaWpoyMzN14sSJYI8EAB1SSMckPz9fWVlZKisrU1ZW\nlvLy8oI9EgB0SGHBHsBXNTU1OnLkiF555RVJUnp6ulauXKna2lpFRUV59TWsVovRDOFR0Ub74+5k\n+rxqK9H28GCPgHbI5Pl5q31DNiZVVVWKi4uTzWaTJNlsNsXGxqqqqsrrmPTs2cVohvsLVhvtj7tT\ndHTXYI8gSVo9/P5gj4B2yF/Pz5A+zQUAaB9CNibx8fE6e/asnE6nJMnpdKq6ulrx8fFBngwAOp6Q\njUl0dLSSkpJUWloqSSotLVVSUpLXp7gAAG3H4na73cEewlcVFRXKzc3VhQsX1L17dxUWFmrgwIHB\nHgsAOpyQjgkAoH0I2dNcAID2g5gAAIwREwCAMWICADAWsu+AR2A0Nzdr3bp1eueddxQWFqZOnTop\nJydHY8eO1f79+zVnzhz179/fc/ulS5fqG9/4hlJTUxUeHi673S5JGjlypJYtWxakR4G7TWpqqjp3\n7qw333xTVqvVs624uFhDhgzRa6+9pu3bt8vlcsnlcmny5MmaM2eOzp8/r+nTp0uSGhsbVV1d7Xn+\nfvvb39aiRYuC9IhCHzHBLRUUFKixsVFvvfWW7Ha7jh49qlmzZqlHjx6SpEGDBun111+/6b4bNmzQ\nkCFDAjkuOpDGxkbt2rVLkydPbrH9jTfe0Pbt27V161YlJCTo/Pnz+v73vy+Xy6V58+Zp165dkqT9\n+/ersLCw1ecv7gynudCq06dP67e//a0KCgo8RxhDhgxRdna2Nm3aFOTp0NHl5ORo06ZNam5ubrF9\n48aNWrJkiRISEiRJPXr00LPPPqstW7Z84bZoO8QErTp69Kj69u2ryMjIFttTUlL0z3/+U9L1N45m\nZGQoIyNDU6ZMaXG7+fPne9bee++9gM2NjiE5OVn33Xefdu7c6dnmdrt16tQppaSktLjtoEGDFBYW\nxjWP/IjTXGiVN+9n5TQXgmnhwoV68skn9fjjj9/2thZL+7g0wN2KIxO0asiQIfrvf/+r+vr6FtsP\nHDige+65J0hTAf9n4MCBGjNmjOe6RhaLRYmJiTpw4ECL21VUVOjq1avq169fMMbsEIgJWpWYmKhx\n48apoKBATU1Nkq6f+iouLlZOTk6QpwOu+8EPfqAdO3aooaFB0vXXUoqKilRVVSVJOn/+vAoKCjR7\n9mzPa39oe5zmwi3l5+dr3bp1Gj9+vL70pS/Jbrfr6aef1ogRI7R///5gjweod+/eysjI0C9/+UtJ\n0uTJk3XlyhXNnDlTbrdbTqdTGRkZmjt3bpAnvbvxQY8AAGOc5gIAGCMmAABjxAQAYIyYAACMERMA\ngDFiAgAwRkyANpaamqq9e/f6/X5yc3P185//3O/3A3iDmAABtH//fn3rW98K9hhAmyMmAABjxAS4\nhRdffFEPPvighg4dqrS0NO3bt+8Lp5dudrTxj3/8Q+PHj9fXv/51LV26VE1NTWpsbNTs2bNVXV2t\noUOHaujQoTp79qwOHTqkzMxMORwOjR49WitWrPBcd8Ptduu5557TqFGjNGzYME2cOFFHjx79wpyX\nLl3StGnTtGrVqlt+2vOf/vQnPfbYYxo2bJjGjBmjjRs3ttF3Ch0dn80FtOLYsWP61a9+pV//+teK\ni4vTqVOn5HK5vNq3pKREL7/8siIiIpSdna3nn39eixYt0tatW7V48WL9+c9/9tz23LlzWrp0qZKT\nk3XmzBnNnj1bO3bs0PTp0/X++++rvLxcZWVl6tatm44dO6Zu3bq1uK+6ujrNnj1b3/zmN2972dmI\niAgVFhbqK1/5io4ePaoZM2YoKSlJY8eOvfNvEPA5HJkArbDZbGpubvZ8fHliYqL69u3r1b5PPPGE\n4uPjFRkZqblz5+qtt95q9bbJyclKSUlRWFiYEhMTlZmZqQ8//FCSFBYWpoaGBh07dkxut1uDBg1S\nbGysZ9/q6mpNmzZN48aN8+r65SNHjtQ999wjq9Wqe++9VxMmTNBf//pXrx4TcCscmQCt6Nevn5Yt\nW6aNGzfq3//+t0aPHq3c3Fyv9o2Pj/f8d0JCgqqrq1u97fHjx/XTn/5Uhw8f1uXLl+V0OnXfffdJ\nkkaNGqUnnnhCK1as0OnTp/Xoo49qyZIl6tq1qyRpz5496ty5s6ZOnerVXAcPHtTatWv16aef6urV\nq2pubta4ceO82he4FY5MgFuYOHGidu7cqXfffVcWi0Vr165VRESErly54rnNZ5999oX9blxLQ5Iq\nKys9RxM3u9pfQUGBBg4cqLKyMv3tb3/TokWLWrzu8eSTT+r111/X7t27deLECb300kuetSlTpujB\nBx/UnDlz1NjYeNvH86Mf/UgPP/yw9uzZo48++khTp0716oqawO0QE6AVx44d0759+9Tc3Kzw8HDZ\n7XZZrVYlJSVpz549qq+v17lz57R9+/Yv7Ltjxw6dOXNG9fX1Ki4u1vjx4yVJ0dHRqq+v18WLFz23\nbWhoUJcuXdSlSxdVVFS0uKb5oUOHdPDgQV29elUREREKDw+X1dryf9u8vDwNGDBA2dnZLSJ3Mw0N\nDerRo4fsdrsOHTqk0tJSk28R4EFMgFY0NzfrZz/7mUaOHKnRo0ertrZWP/zhD5WRkaF7771Xqamp\nmjFjhicUn5eenq4ZM2Zo7Nix6tu3r+fCTIMGDdKECRM0duxYORwOnT17VkuWLFFpaamGDRumZ555\npsXXa2ho0PLlyzVixAg99NBDioyM1MyZM1vcl8Vi0cqVK9W7d2/NmzfPc1XMm8nPz9eGDRs0dOhQ\nbd68Wd/5znfa6LuFjo6LYwEAjHFkAgAwxl9zAXeZCRMmqLKy8gvbn332WU2aNCkIE6Ej4DQXAMAY\np7kAAMaICQDAGDEBABgjJgAAY8QEAGDsf4t5Ezxm3YlPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "subtask_a\n",
            "NOT    8840\n",
            "OFF    4400\n",
            "Name: id, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyyLmYKDvhLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [1] SMOTE + ADA-SYN + Tomek links -> use preferably exclusive with [2]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "352nAj4Spt06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [2] Levelling instances importance -> use peferably exclusive with [1]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}