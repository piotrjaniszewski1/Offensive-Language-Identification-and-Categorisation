{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "albert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b65b96c3750e48b6ba03ce279c625f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5448e8f37514be4872b67ed43000610",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e5a8bf25d594f35a231f56d3f864d4a",
              "IPY_MODEL_9316c6ebd3984a068a1881702fb27a61"
            ]
          }
        },
        "c5448e8f37514be4872b67ed43000610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e5a8bf25d594f35a231f56d3f864d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76644df2201e430cb9829aaa7e6cb968",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 11916,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11916,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e12aae9fee9421d88e8f64fa7f1f893"
          }
        },
        "9316c6ebd3984a068a1881702fb27a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a83fafbd3c024812b48a2e06a47ddefa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 11916/11916 [00:04&lt;00:00, 2714.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8abe820d394c455295790cfd17e789f0"
          }
        },
        "76644df2201e430cb9829aaa7e6cb968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e12aae9fee9421d88e8f64fa7f1f893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a83fafbd3c024812b48a2e06a47ddefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8abe820d394c455295790cfd17e789f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d973e8c8fdc7455b8a49c9dda6090d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e883f71b0a2242c882c61951457ae9b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa223d4daa434277b9a9d86ad775955e",
              "IPY_MODEL_a41882360f4e4f40b912f911e0e1e7bc"
            ]
          }
        },
        "e883f71b0a2242c882c61951457ae9b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa223d4daa434277b9a9d86ad775955e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_938af0343b6b4ffaaa731b57b8869aff",
            "_dom_classes": [],
            "description": "Epoch",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7f6492fa6b545538dccfe5b9fc0b68e"
          }
        },
        "a41882360f4e4f40b912f911e0e1e7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3cbd2e78e294b4087578c213d8b0fcd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 5/5 [1:25:18&lt;00:00, 1023.73s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2ff90a100b04a0c93d04b27d7666ad6"
          }
        },
        "938af0343b6b4ffaaa731b57b8869aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7f6492fa6b545538dccfe5b9fc0b68e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3cbd2e78e294b4087578c213d8b0fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2ff90a100b04a0c93d04b27d7666ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6971012519040148f2c245238ce5535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e96dd199b2a94df8a4171401ae685731",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8472b28ea9c84559a47d1ffefdca141d",
              "IPY_MODEL_47766eeecd7a421aa5643a1b92e0b5c8"
            ]
          }
        },
        "e96dd199b2a94df8a4171401ae685731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8472b28ea9c84559a47d1ffefdca141d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e396a07924a94eb996a12afe67a90570",
            "_dom_classes": [],
            "description": "Current iteration",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1490,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42f4968c30fe445f8c274ca8a0535e7d"
          }
        },
        "47766eeecd7a421aa5643a1b92e0b5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ce026d6033f456ebc1a36849f21beba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1490/1490 [17:04&lt;00:00,  1.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c79ebf6839d74f06b343e2873db9c727"
          }
        },
        "e396a07924a94eb996a12afe67a90570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42f4968c30fe445f8c274ca8a0535e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ce026d6033f456ebc1a36849f21beba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c79ebf6839d74f06b343e2873db9c727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9804a9836c464bffb1655cdfda45cc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0773f29d5eb54f069098ecd518a60b81",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a2c952321ec4820b0ffec329db6e025",
              "IPY_MODEL_fe88dd88e96b42a3bb7610e1b69551c6"
            ]
          }
        },
        "0773f29d5eb54f069098ecd518a60b81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a2c952321ec4820b0ffec329db6e025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4b58730bc1640abba5c1cef39bdd8b3",
            "_dom_classes": [],
            "description": "Current iteration",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1490,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b411b4800f14ccb8a508c37e8c860d0"
          }
        },
        "fe88dd88e96b42a3bb7610e1b69551c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ecdf92d63184133b3ab2c6194b4cc16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1490/1490 [17:03&lt;00:00,  1.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4efd2779701d49698c47de9f34a0fc94"
          }
        },
        "f4b58730bc1640abba5c1cef39bdd8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b411b4800f14ccb8a508c37e8c860d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ecdf92d63184133b3ab2c6194b4cc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4efd2779701d49698c47de9f34a0fc94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d13264a15ae495683e78c4da3fae69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2bf53c52c9c5440d9f4f870878fe4887",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_248700e360294353ae3ddea51c18926b",
              "IPY_MODEL_60517057ecd9458fb859ac0be3502ff6"
            ]
          }
        },
        "2bf53c52c9c5440d9f4f870878fe4887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "248700e360294353ae3ddea51c18926b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc330254f4f44c5dbe18c6541cc3ada0",
            "_dom_classes": [],
            "description": "Current iteration",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1490,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_758a8b752f294aa781ac9ebdc830ee1a"
          }
        },
        "60517057ecd9458fb859ac0be3502ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e2444d69d614343860eed442ee620b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1490/1490 [17:03&lt;00:00,  1.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25a23e86bcba4313b16db8a58663fd76"
          }
        },
        "bc330254f4f44c5dbe18c6541cc3ada0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "758a8b752f294aa781ac9ebdc830ee1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e2444d69d614343860eed442ee620b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25a23e86bcba4313b16db8a58663fd76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d407fb23ef5c43eeaf4f3327fd3b1873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3933afb769d0452781a49b5ee040bbc8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_033e2280b9f640fc8e40cd6346e38e20",
              "IPY_MODEL_932844c55eef43c1a6628b434018536d"
            ]
          }
        },
        "3933afb769d0452781a49b5ee040bbc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "033e2280b9f640fc8e40cd6346e38e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85c24dda3fc44a1faa30d3240a25725b",
            "_dom_classes": [],
            "description": "Current iteration",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1490,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d729771091c4eb785328c71451951d9"
          }
        },
        "932844c55eef43c1a6628b434018536d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45ec2ab8496649ecaa39eff3e8188698",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1490/1490 [17:02&lt;00:00,  1.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02c9fb1b93fb453883820de81cb3312e"
          }
        },
        "85c24dda3fc44a1faa30d3240a25725b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d729771091c4eb785328c71451951d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45ec2ab8496649ecaa39eff3e8188698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02c9fb1b93fb453883820de81cb3312e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5991b6a2e4940ae9c28334f5c22fc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ccf7c059bc54eb0aa6ea57e41338134",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c890bec13b940d3906472df4e952d5f",
              "IPY_MODEL_b07a76b3dfa54db78d83f17b257c4829"
            ]
          }
        },
        "4ccf7c059bc54eb0aa6ea57e41338134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c890bec13b940d3906472df4e952d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c00b8856b8c443aea032470ffe403662",
            "_dom_classes": [],
            "description": "Current iteration",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1490,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc98cd6e7e2a45b6ab759819422d1bb0"
          }
        },
        "b07a76b3dfa54db78d83f17b257c4829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ac8286998cf4553b064492b9f73a45a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1490/1490 [17:03&lt;00:00,  1.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_832a34a8483542abaab13572305cec98"
          }
        },
        "c00b8856b8c443aea032470ffe403662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc98cd6e7e2a45b6ab759819422d1bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ac8286998cf4553b064492b9f73a45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "832a34a8483542abaab13572305cec98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6aca32bf969b460bbb67860e569ac2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fdac0fc7e3348d1a0f8cf75619ac6ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29e6bee05196477a8dc41502c65fdf4a",
              "IPY_MODEL_7b1457874dc5492c9d5bcd39581f0df3"
            ]
          }
        },
        "4fdac0fc7e3348d1a0f8cf75619ac6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29e6bee05196477a8dc41502c65fdf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba288174e3e747d189a65411449387de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 860,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 860,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13a94b2aedfa4de2b4fae9f89810e646"
          }
        },
        "7b1457874dc5492c9d5bcd39581f0df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57e26a7d3af64bc58286e97a41acf3ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 860/860 [00:00&lt;00:00, 2303.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3205006f67c4183894bbf54e3955cfd"
          }
        },
        "ba288174e3e747d189a65411449387de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13a94b2aedfa4de2b4fae9f89810e646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57e26a7d3af64bc58286e97a41acf3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3205006f67c4183894bbf54e3955cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c105877e4d8343fda5163d8163a2391a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a9c5aa09a774cc69a73d1e29a0db612",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f2db84ea5374618bb0677b1e6a79d1c",
              "IPY_MODEL_5ea549101ae042b48ea4a8d00a231e39"
            ]
          }
        },
        "6a9c5aa09a774cc69a73d1e29a0db612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f2db84ea5374618bb0677b1e6a79d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df63dcf6332d4dbe8818c9ae93cc1db6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 108,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92ae2246f0794b90906f58ba7d1c0f79"
          }
        },
        "5ea549101ae042b48ea4a8d00a231e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee503e1c4878445db4a3ea8ea3596632",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 108/108 [00:25&lt;00:00,  4.95it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d1097fbfcc5473e94e62015619a456c"
          }
        },
        "df63dcf6332d4dbe8818c9ae93cc1db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92ae2246f0794b90906f58ba7d1c0f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee503e1c4878445db4a3ea8ea3596632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d1097fbfcc5473e94e62015619a456c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y38PprNWUWon",
        "colab_type": "text"
      },
      "source": [
        "# SemEval 2020 Task 12: OffensEval2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FdeLhrv_PYl",
        "colab_type": "text"
      },
      "source": [
        "## Installing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTTzs91c_OaI",
        "colab_type": "code",
        "outputId": "d55b863e-f8f4-40f6-f542-2ba013b702ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        }
      },
      "source": [
        "# Install necessary packages\n",
        "\n",
        "!pip install unidecode\n",
        "!pip install contractions\n",
        "!pip install wordsegment\n",
        "!pip install -U symspellpy\n",
        "!pip install emoji --upgrade\n",
        "!pip install -U imbalanced-learn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n",
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/85/41/c3dfd5feb91a8d587ed1a59f553f07c05f95ad4e5d00ab78702fbf8fe48a/contractions-0.0.24-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Building wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81705 sha256=4db77fbd4740b84d6dc025f9c872bdce34aa0bb6572ca1cf1183f757e325428e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, textsearch, contractions\n",
            "Successfully installed contractions-0.0.24 pyahocorasick-1.4.0 textsearch-0.0.17\n",
            "Collecting wordsegment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/6c/e6f4734d6f7d28305f52ec81377d7ce7d1856b97b814278e9960183235ad/wordsegment-1.3.1-py2.py3-none-any.whl (4.8MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8MB 3.1MB/s \n",
            "\u001b[?25hInstalling collected packages: wordsegment\n",
            "Successfully installed wordsegment-1.3.1\n",
            "Collecting symspellpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/0b/2daa14bf1ed649fff0d072b2e51ae98d8b45cae6cf8fdda41be01ce6c289/symspellpy-6.5.2-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.17.5)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.5.2\n",
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42175 sha256=5e725ebc2f211ef97b86089ca3e2cb84d519c18d159ff83724d6cfee061ba85d\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n",
            "Collecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/aa/eba717a14df36f0b6f000ebfaf24c3189cd7987130f66cc3513efead8c2a/imbalanced_learn-0.6.1-py3-none-any.whl (162kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOWGCPhL1ooD",
        "colab_type": "text"
      },
      "source": [
        "### Mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKFacKxupkVY",
        "colab_type": "code",
        "outputId": "ddac54ed-ff40-4583-c7d5-cf92f1531a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH_TO_DIR = '/content/drive/My Drive/STUDIA/SEM 9/pracownia/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXtKi4bVUmV3",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LP7i81J8twMn",
        "outputId": "a8812245-08b6-4fc5-e223-1ac8c6616973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "# All imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from bs4 import BeautifulSoup\n",
        "import unidecode\n",
        "import contractions\n",
        "import gensim.downloader as api\n",
        "import re\n",
        "import wordsegment\n",
        "import pkg_resources\n",
        "from symspellpy.symspellpy import SymSpell, Verbosity\n",
        "import emoji\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "wordsegment.load()\n",
        "\n",
        "# Load SymSpell -> package for correcting misspellings\n",
        "sym_spell = SymSpell(2, 7)\n",
        "\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "bigram_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
        "\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mER1mPUtiaPl",
        "outputId": "9a680752-dc53-49fd-90c7-e721146c047f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "#Import data\n",
        "training_examples_url = 'https://raw.githubusercontent.com/piotrjaniszewski1/SemEval-2020-Task12/master/data2019/olid-training-v1.0.tsv'\n",
        "training_dataset = pd.read_csv(training_examples_url, delimiter='\\t')\n",
        "print(training_dataset.head())\n",
        "test_tweets_url = 'https://raw.githubusercontent.com/piotrjaniszewski1/SemEval-2020-Task12/master/data2019/testset-levela.tsv'\n",
        "test_tweets = pd.read_csv(test_tweets_url, delimiter='\\t')\n",
        "print(test_tweets.head())\n",
        "test_labels_url = 'https://raw.githubusercontent.com/piotrjaniszewski1/SemEval-2020-Task12/master/data2019/labels-levela.csv'\n",
        "test_labels = pd.read_csv(test_labels_url, delimiter=',', header=None, names=[\"id\", \"label\"])\n",
        "print(test_labels.head())\n",
        "test_dataset = test_tweets.set_index(\"id\").join(test_labels.set_index(\"id\"))\n",
        "test_dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      id                                              tweet  ... subtask_b subtask_c\n",
            "0  86426  @USER She should ask a few native Americans wh...  ...       UNT       NaN\n",
            "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...  ...       TIN       IND\n",
            "2  16820  Amazon is investigating Chinese employees who ...  ...       NaN       NaN\n",
            "3  62688  @USER Someone should'veTaken\" this piece of sh...  ...       UNT       NaN\n",
            "4  43605  @USER @USER Obama wanted liberals &amp; illega...  ...       NaN       NaN\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "      id                                              tweet\n",
            "0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...\n",
            "1  27014  #ConstitutionDay is revered by Conservatives, ...\n",
            "2  30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...\n",
            "3  13876  #Watching #Boomer getting the news that she is...\n",
            "4  60133  #NoPasaran: Unity demo to oppose the far-right...\n",
            "      id label\n",
            "0  15923   OFF\n",
            "1  27014   NOT\n",
            "2  30530   NOT\n",
            "3  13876   NOT\n",
            "4  60133   OFF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15923</th>\n",
              "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27014</th>\n",
              "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30530</th>\n",
              "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13876</th>\n",
              "      <td>#Watching #Boomer getting the news that she is...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60133</th>\n",
              "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet label\n",
              "id                                                            \n",
              "15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   OFF\n",
              "27014  #ConstitutionDay is revered by Conservatives, ...   NOT\n",
              "30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...   NOT\n",
              "13876  #Watching #Boomer getting the news that she is...   NOT\n",
              "60133  #NoPasaran: Unity demo to oppose the far-right...   OFF"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-xHoiMYYlJQk",
        "colab": {}
      },
      "source": [
        "seed = 13\n",
        "\n",
        "# prepare training examples\n",
        "training_examples_A = training_dataset['tweet'][training_dataset['subtask_a'].notnull()]\n",
        "training_examples_B = training_dataset['tweet'][training_dataset['subtask_b'].notnull()]\n",
        "training_examples_C = training_dataset['tweet'][training_dataset['subtask_c'].notnull()]\n",
        "\n",
        "# prepare test examples and labels\n",
        "test_examples_A = test_dataset['tweet'][test_dataset['label'].notnull()]\n",
        "test_labels_A = (test_dataset['label'][test_dataset['label'].notnull()] == 'OFF').astype(int)\n",
        "\n",
        "# prepare training labels\n",
        "training_labels_A = (training_dataset['subtask_a'][training_dataset['subtask_a'].notnull()] == 'OFF').astype(int)\n",
        "training_labels_B = (training_dataset['subtask_b'][training_dataset['subtask_b'].notnull()] == 'TIN').astype(int)\n",
        "c_mapping = {'IND': 0, 'GRP': 1, 'OTH': 2}\n",
        "training_labels_C = training_dataset['subtask_c'][training_dataset['subtask_c'].notnull()].replace(c_mapping)\n",
        "\n",
        "# split training set into training and validation\n",
        "training_examples_A, validation_examples_A, training_labels_A, validation_labels_A = train_test_split(\n",
        "    training_examples_A, training_labels_A, test_size=0.1, stratify=training_labels_A, random_state=seed)\n",
        "training_examples_B, validation_examples_B, training_labels_B, validation_labels_B = train_test_split(\n",
        "    training_examples_B, training_labels_B, test_size=0.1, stratify=training_labels_B, random_state=seed)\n",
        "training_examples_C, validation_examples_C, training_labels_C, validation_labels_C = train_test_split(\n",
        "    training_examples_C, training_labels_C, test_size=0.1, stratify=training_labels_C, random_state=seed)\n",
        "\n",
        "training_x = list(training_examples_A)\n",
        "validation_x = list(validation_examples_A)\n",
        "training_y = list(training_labels_A)\n",
        "validation_y = list(validation_labels_A)\n",
        "test_x = list(test_examples_A)\n",
        "test_y = list(test_labels_A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2bNpHc9qMpw",
        "colab_type": "text"
      },
      "source": [
        "## **Preprocessing** (used as alternative to albert preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fao-Vte1gtJ2",
        "colab_type": "text"
      },
      "source": [
        "### Common preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re0mCq1ogs6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove html tags if exist\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    stripped_text = soup.get_text(separator=' ')\n",
        "    return stripped_text\n",
        "\n",
        "\n",
        "# remove unnecessary whitespaces\n",
        "def remove_whitespace(text):\n",
        "    text = text.strip()\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "\n",
        "# remove accented chars (e.g. caffè -> caffe)\n",
        "def remove_accented_chars(text):\n",
        "    text = unidecode.unidecode(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# remove hashes and split words (e.g. '#fortTrump' -> 'fort trump')\n",
        "def split_hashtags(text):\n",
        "    splitted = text.split()\n",
        "    new_word_sequence = []\n",
        "\n",
        "    for chunk in splitted:\n",
        "        if chunk[0] == '#':\n",
        "            chunk = chunk[1:]\n",
        "            new_word_sequence.extend(wordsegment.segment(chunk))\n",
        "        else:\n",
        "            new_word_sequence.append(chunk)\n",
        "        \n",
        "    return ' '.join(tuple(new_word_sequence))\n",
        "\n",
        "\n",
        "def substitute_emojis(text):\n",
        "    demojized_text = emoji.demojize(text)\n",
        "    return re.compile('[_:]+').sub(' ', demojized_text)\n",
        "\n",
        "\n",
        "def preprocess_common(text):\n",
        "    text = strip_html_tags(text)\n",
        "    text = contractions.fix(text)\n",
        "    text = split_hashtags(text)\n",
        "    text = substitute_emojis(text)\n",
        "    text = remove_whitespace(text)\n",
        "    text = remove_accented_chars(text)\n",
        "    return text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gsfta6kbMt46",
        "colab": {}
      },
      "source": [
        "# Remove redundant @user tokens\n",
        "def remove_redundant_users(example):\n",
        "  user_count = 0\n",
        "  new_example = example[:]\n",
        "  for i, token in reversed(list(enumerate(example))):\n",
        "    if token == '@user':\n",
        "      user_count += 1\n",
        "      if user_count > 3:\n",
        "        new_example.pop(i)\n",
        "\n",
        "    else:\n",
        "      user_count = 0\n",
        "\n",
        "  return new_example\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pJMq-8ygixr",
        "colab_type": "text"
      },
      "source": [
        "### Spacy preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPYd37I_giKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# exclude negation words from spacy stopwords list\n",
        "deselect_stop_words = ['no', 'not', 'noone', 'none', 'lacks', 'lack', 'nor', 'never', 'neighter', 'hardly', 'nobody', 'nothing', 'lacking', 'nowhere']\n",
        "for w in deselect_stop_words:\n",
        "    nlp.vocab[w].is_stop = False\n",
        "\n",
        "def preprocess_spacy(text):\n",
        "    text = text.lower()\n",
        "    doc = nlp(text)\n",
        "\n",
        "    clean_text = []\n",
        "    \n",
        "    for token in doc:\n",
        "        flag = True\n",
        "        edit = token.text\n",
        "\n",
        "        # remove punctuations\n",
        "        if token.pos_ == 'PUNCT' and flag == True and token.text != '@user': \n",
        "            flag = False\n",
        "       \n",
        "        # remove special characters\n",
        "        if token.pos_ == 'SYM' and flag == True: \n",
        "            flag = False\n",
        "        \n",
        "        # remove numbers\n",
        "        if (token.pos_ == 'NUM' or token.text.isnumeric()) and flag == True:\n",
        "            flag = False\n",
        "\n",
        "        # correct misspelings\n",
        "        # if flag == True:\n",
        "        #     suggestions = sym_spell.lookup(edit, Verbosity.TOP, 2)\n",
        "        #     if len(suggestions) > 0:\n",
        "        #         edit = suggestions[0].term\n",
        "\n",
        "        # remove stop words\n",
        "        if token.is_stop and token.pos_ != 'NUM': \n",
        "            flag = False\n",
        "\n",
        "        # convert tokens to base form\n",
        "        elif token.lemma_ != '-PRON-' and flag == True:\n",
        "            edit = token.lemma_\n",
        "\n",
        "        # append tokens edited and not removed to list \n",
        "        if edit != '' and flag == True:\n",
        "            clean_text.append(edit)        \n",
        "    \n",
        "    return clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBRELPK-NfGy",
        "colab_type": "text"
      },
      "source": [
        "### Joint preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGuryVpCNeKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def full_preprocessing(example):\n",
        "    basic_preprocessed = preprocess_common(example)\n",
        "    cleaned_example = preprocess_spacy(basic_preprocessed)\n",
        "    return remove_redundant_users(cleaned_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlyyCkwWhFw1",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "801387df-b5fb-411d-ee98-910ba5f3f7fd",
        "id": "ZU7vnLGUMt4_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# normalization -> papers, complicated solutions, replace abbreviations with full names (e.g. MAGA)\n",
        "# check removing less stop words (some may have some significance)\n",
        "\n",
        "cleaned_x = [full_preprocessing(example) for example in training_x[0:30]]\n",
        "print(cleaned_x[0:30])\n",
        "print(training_x[0:30])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['@user', '@user', '@user', 'know', 'belong', 'violent', 'liberal', 'antifa', 'party', 'w/', 'kkk', 'hood', 'beat', 'total', 'stranger', '&', 'fund', 'party', 'violent', '&', 'corrupt', 'party', 'try', 'pour', 'tear', '&', 'believe', 'heart', 'hard', 'sell', 'include', 'voter'], ['@user', 'lie', 'corrupt', 'traitor', 'nobody', 'want', 'hear', 'anymore', 'lie', 'deep', 'state', 'corruption', 'url'], ['@user', '@user', 'typical', 'liberal', 'principle', 'come', 'money'], ['@user', 'know', 'add', 'million', '@user', 'donation', 'receive', 'access'], ['@user', 'idiot', 'fringe', 'right', 'hate', 'conservative'], ['@user', '@user', '@user', 'think', 'conservative', 'one', 'try', 'rewrite', 'history', 'think', 'face', 'url'], ['@user', '@user', '@user', 'link', 'article', 'show', 'wrong', 'tell', 'libertarian', 'conservative', 'aka', 'right', 'supposedly', 'believe', 'not', 'bigote', 'pattern', 'notice', 'never', 'wrong'], ['@user', 'grit', 'tooth', 'blonde', 'break', 'shield', 'feeling', 'pump', 'blonde', 'charge', 'get', 'toss', 'dart', 'aim', 'leg', 'minor', 'pain', 'tough'], ['@user', 'term', 'parasite', 'add', 'list', 'fuck', 'term', 'include', 'term', 'widget'], ['@user', '@user', '@user', 'speak', 'antifa', 'blm', 'say', 'lie'], ['@user', 'antifa', 'burn', 'conservative', 'house', 'cnn', 'light', 'torch', '&', 'throw', 'gas', 'flame'], ['@user', '@user', '@user', 'want', 'define', 'pul', 'ease', 'live', 'msmedia', 'shit', 'smear', 'point', 'marxine', 'water', 'send', 'antifa', 'minion', 'threaten', 'public', 'place', 'learn', 'not', 'f*ck', 'pavlovian', 'leave', 'think', 'night', 'night', 'crescent', 'moon'], ['@user', 'thank', 'goodness', 'not', 'mn', 'passive', 'aggressive', 'love'], ['@user', '@user', 'ford', 'conservative', 'hate', 'display', 'democratic', 'freedom', 'attack', 'canadian', 'charter', 'right', 'freedom', 'hate', 'minority', 'constitutional', 'right', 'conservative', 'attack', 'democracy', 'canada', 'cpc', 'political', 'hate', 'group'], ['@user', '@user', '@user', 'false', 'roll', 'floor', 'laugh'], ['@user', '@user', '@user', 'defend', '2nd', 'not', 'nra', '1st', 'join', 'promote', '&', 'educate', 'gun', 'owner', '&', 'public', 'gun', 'no', 'hypocrisy', 'amy', 'maybe', 'fyi', 'know', 'lot', 'liberal', 'member', 'nra', 'not', 'agree'], ['@user', '@user', '@user', 'misdrawe', 'not', 'white', 'blonde', 'answer'], ['@user', '@user', '@user', 'not', 'mention', 'jim', 'seriously', 'medical', 'condition', 'sjw', 'tactic', 'sargon', 'seriously', 'antifa'], ['@user', '@user', 'dem', 'libs', 'real', 'job', 'sure', 'lot', 'free', 'time'], ['@user', '@user', '@user', 'exactly', 'liberal', 'dem', 'think', 'people', 'right', 'funny', 'pit', 'interest', 'similar', 'nuance', 'criminal', 'defense', 'attorney', 'fight', 'day', 'protect', 'bill', 'right'], ['@user', 'patient', 'autism', 'cap'], ['@user', '@user', 'mean', 'superman', 'pleaseeeeee', 'fold', 'hand', 'medium', 'light', 'skin', 'tone', 'fold', 'hand', 'medium', 'light', 'skin', 'tone', 'fold', 'hand', 'medium', 'light', 'skin', 'tone', 'fold', 'hand', 'medium', 'light', 'skin', 'tone'], ['bunch', 'self', 'aggrandize', 'liberal', 'fancy', 'dress', 'mock', 'trump', 'fancy', 'dress', 'sound', 'lot', 'like', 'dem', 'try', 'lynch', 'kavanaugh', 'politic', 'witchhunt', 'url'], ['@user', 'generous', 'offer'], ['@user', 'hello', 'twin', 'let', 'ke', 'correct', 'typoness', 'group', 'g)i', 'dle', 'case', 'lazy', 'use', 'use', 'idle', 'instead', 'wink', 'face'], ['@user', '@user', '@user', 'bwahahaha', 'work', 'liberal', 'tool', 'honest', 'work', 'conservative', 'depend', 'support', 'chubby', 'little', 'self', 'hear', 'get', 'free', 'food', 'protester'], ['republican', 'conservative', '@user', 'wet', 'dream', 'step', 'confirm', 'predator', 'scotus', 'judge', 'step', 'eliminate', 'woman', 'choice', 'step', 'eliminate', 'non', 'white', 'voting', 'right', 'step', 'eliminate', 'woman', 'voting', 'right', 'step', 'end', 'immigration'], ['wcw', 'look', 'beautiful', 'wish', 'beauty', 'tho', 'love', 'baby', 'sister', 'smile', 'face', 'heart', 'eye', 'weary', 'face', 'red', 'heart', '@user', 'url'], ['@user', '@user', '@user', 'say', 'antifa', 'never', 'oppress', 'nazi', 'gotcha'], ['@user', '@user', 'able', 'reconnect', 'mind', 'try', 'crossed', 'finger']]\n",
            "['@USER @USER @USER We do know she belongs to the violent liberal Antifa party who w/ their KKK HOODS beat up total strangers &amp; are funded to do so by her party. Most violent &amp; corrupt party trying to now pour on the tears &amp; get us to believe they have a heart. Hard sell to anyone including voters!', '@USER you are a lying corrupt traitor!!! Nobody wants to hear anymore of your lies!!! #DeepStateCorruption URL', '@USER @USER Typical liberals. Principled until it comes to their money.', '@USER Because she knew how to add up the millions in @USER donations received for access?', '@USER Those idiots are fringe right. They are hated by most conservatives.', '@USER @USER @USER I thought conservatives were the ones trying to rewrite history? 🤔 URL', '@USER @USER @USER I linked to an article showing you why you\\'re wrong. You\\'re telling libertarians and conservatives\" aka the right what they supposedly believe. I\\'m not bigoted, it\\'s just a pattern I\\'ve noticed that never seems to be wrong.\"', '@USER Gritting her teeth, the blonde then broke her shield and feeling pumped the blonde charged after him. Give me all you got!\" She then tossed some of her darts, aiming for his legs and would cause only minor pain. \"Show me how tough you are!\"\"', '@USER The term parasite\" has now been added to my list of \"fuck you\" terms, which also includes the term \"widget\".\"', '@USER @USER @USER @USER @USER I just spoke with ANTIFA and BLM. They said you lied.', '@USER Antifa would burn a Conservatives house down and CNN would be there lighting the torches &amp; throwing gas on the flames.', '@USER @USER @USER @USER @USER ...how you want to be defined\"? PUL-EASE! When you live under a 24/7/365 MSMedia SHIT-SMEAR to the point you have Marxine Waters sending her ANTIFA minions out to threaten you in public places - you learn not to give a F*CK what the \"Pavlovian Left\" thinks. Night, night 🌙!\"', '@USER Thank goodness he is not MN passive aggressive. Love it!!', '@USER @USER Ford and the conservatives hates the displays of democratic freedoms hence their attacks on the Canadian charter of rights and freedoms and their hate for minorities constitutional rights #conservativesattackondemocracy in #canada #theCPCisapoliticalhategroup', '@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER False 🤣', \"@USER @USER @USER @USER @USER 3) I will always defend the 2nd. But not the NRA who when I 1st joined was about promoting &amp; educating gun owners &amp; the public about guns. No hypocrisy here Amy well except maybe on your part. FYI I know a lot of Liberals that a members of the NRA. I don't always agree with them\", '@USER @USER @USER Misdrawed. Cause she is not white and blonde. Why he did that? Can you answer that?', '@USER @USER @USER Not to mention that Jim seriously has a medical condition. What an SJW tactic to take. Sargon seriously has become what ANTIFA is .', '@USER @USER Do any Dems/libs have a real job?? They sure have a lot of free time!!', \"@USER @USER @USER That is exactly what liberals and Dems think about people on the right. It's funny how we've been pitted against each other when really our interests are all very similar with just some nuances. I'm a criminal defense attorney and I fight every day to protect our bill of rights.\", '@USER Be patient with us we have autism\" Cap!\"', '@USER @USER does that mean He still our #superman ? Pleaseeeeee say he is 🙏🏼🙏🏼🙏🏼🙏🏼', '... a bunch of self-aggrandizing liberals in fancy dresses mocking Trump.” Except for the fancy dresses, sounds a lot like the Dems who are trying to lynch Kavanaugh... #politics #MeTooWitchhunt URL', '@USER He is so generous with his offers.', '@USER Hello, twin. Let ke correcting your typoness. Our group name is (G)I-DLE in case you are too lazy to use ()\" or \"-\" , you can use IDLE instead 😉\"', '@USER @USER @USER @USER Bwahahaha-work? They are Liberal tools,honest work is for the Conservatives who they depend on to support their chubby little selves. Also,I hear they are getting $50 (and free food) to be protesters.\"\"', \"#Republicans #Conservatives @USER wet dreams: Step 1: Confirm predator as SCOTUS judge Step 2: Eliminate women's choice Step 3: Eliminate non white's voting rights Step 4: Eliminate women's voting rights Step 5: End immigration\", '#wcw because look at how beautiful she is!!!!!! I wish I had this beauty tho but I am just in love with my baby sister 😍😩❤️ @USER URL', \"@USER @USER @USER @USER @USER @USER @USER @USER So you're saying Antifa should have never oppressed the Nazis... gotcha.\", '@USER @USER You may be able to reconnect now. Mind trying for us? 🤞']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0YQkm4ooK3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessed_train = [full_preprocessing(example) for example in training_x]\n",
        "preprocessed_valid = [full_preprocessing(example) for example in validation_x]\n",
        "preprocessed_test = [full_preprocessing(example) for example in test_x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3LIsPZKU6kN",
        "colab_type": "text"
      },
      "source": [
        "### Class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hMEzRiyEsxDV",
        "outputId": "e8b0545f-7aba-471a-f7df-a5989d560ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "#Depict class imbalance for the subtask A\n",
        "sns.set(font_scale=1.0)\n",
        "countplt=sns.countplot(x='subtask_a', data=training_dataset, palette ='hls')\n",
        "plt.show()\n",
        "\n",
        "print(training_dataset.groupby('subtask_a').count()['id'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEMCAYAAAABLFv3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "subtask_a\n",
            "NOT    8840\n",
            "OFF    4400\n",
            "Name: id, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVbp-kx8nnGm",
        "colab_type": "text"
      },
      "source": [
        "## Helper functins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUhNjpb55ap3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_checkpoint(name):\n",
        "    return ModelCheckpoint(PATH_TO_DIR + 'models/' + name,\n",
        "                     monitor='val_loss',\n",
        "                     mode='min',\n",
        "                     verbose=1,\n",
        "                     save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbnWNHwH5xtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Loss')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.plot(history.history['precision_m'])\n",
        "    plt.plot(history.history['val_precision_m'])\n",
        "    plt.title('Precision')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.plot(history.history['recall_m'])\n",
        "    plt.plot(history.history['val_recall_m'])\n",
        "    plt.title('Recall')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.plot(history.history['f1_m'])\n",
        "    plt.plot(history.history['val_f1_m'])\n",
        "    plt.title('F1')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DmN-x8-FgAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4DvYS5oHBam",
        "colab_type": "code",
        "outputId": "a2b44ac9-de89-4378-ff53-9b5af870f197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                            np.unique(training_y),\n",
        "                                            training_y)\n",
        "class_weights /= max(class_weights)\n",
        "class_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.49773756, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH-6kHUmZ7Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_loss(actual, predicted):\n",
        "    bce = tf.keras.losses.BinaryCrossentropy()\n",
        "    loss = bce(actual, predicted)\n",
        "   \n",
        "    return tf.keras.backend.mean(loss * class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N5Lr5iI3aIs",
        "colab_type": "text"
      },
      "source": [
        "## Albert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJtR1wbxng_0",
        "colab_type": "text"
      },
      "source": [
        "### Our preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uh03Xdn3eSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctation(tokens):\n",
        "    punctuation = [char for char in string.punctuation]\n",
        "    return list(filter(lambda token: token not in punctuation, tokens))\n",
        "\n",
        "\n",
        "def preprocess_bert_before_tokenization(text):\n",
        "    cleaned_x = preprocess_common(text)\n",
        "    # spacy_x = preprocess_spacy(preprocessed_text)\n",
        "    # cleaned_x = remove_redundant_users(spacy_x)\n",
        "    return cleaned_x\n",
        "\n",
        "\n",
        "def preprocess_bert_after_tokenization(tokenized_x):\n",
        "    # update input_ids, input_mask, input_type_ids\n",
        "    return remove_punctation(cleaned_x) # remove i.a. hyphens remainings from words like 'de-platforming'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_evVF-Ja68dH",
        "colab_type": "code",
        "outputId": "13ea26ab-cdcc-4318-a0bc-d266f8c0b2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "training_x[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@USER @USER @USER We do know she belongs to the violent liberal Antifa party who w/ their KKK HOODS beat up total strangers &amp; are funded to do so by her party. Most violent &amp; corrupt party trying to now pour on the tears &amp; get us to believe they have a heart. Hard sell to anyone including voters!',\n",
              " '@USER you are a lying corrupt traitor!!! Nobody wants to hear anymore of your lies!!! #DeepStateCorruption URL',\n",
              " '@USER @USER Typical liberals. Principled until it comes to their money.',\n",
              " '@USER Because she knew how to add up the millions in @USER donations received for access?',\n",
              " '@USER Those idiots are fringe right. They are hated by most conservatives.',\n",
              " '@USER @USER @USER I thought conservatives were the ones trying to rewrite history? 🤔 URL',\n",
              " '@USER @USER @USER I linked to an article showing you why you\\'re wrong. You\\'re telling libertarians and conservatives\" aka the right what they supposedly believe. I\\'m not bigoted, it\\'s just a pattern I\\'ve noticed that never seems to be wrong.\"',\n",
              " '@USER Gritting her teeth, the blonde then broke her shield and feeling pumped the blonde charged after him. Give me all you got!\" She then tossed some of her darts, aiming for his legs and would cause only minor pain. \"Show me how tough you are!\"\"',\n",
              " '@USER The term parasite\" has now been added to my list of \"fuck you\" terms, which also includes the term \"widget\".\"',\n",
              " '@USER @USER @USER @USER @USER I just spoke with ANTIFA and BLM. They said you lied.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKtL8Sc65_pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessed_train = [preprocess_bert_before_tokenization(example) for example in training_x]\n",
        "preprocessed_valid = [preprocess_bert_before_tokenization(example) for example in validation_x]\n",
        "preprocessed_test = [preprocess_bert_before_tokenization(example) for example in test_x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTk9iRxI75ce",
        "colab_type": "code",
        "outputId": "7049109a-9c56-45ce-a038-a666f5f0a2c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "preprocessed_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@user @user @user we do know she belongs to the violent liberal antifa party who w/ their kkk hoods beat up total strangers & are funded to do so by her party. most violent & corrupt party trying to now pour on the tears & get us to believe they have a heart. hard sell to anyone including voters!',\n",
              " '@user you are a lying corrupt traitor!!! nobody wants to hear anymore of your lies!!! deep state corruption url',\n",
              " '@user @user typical liberals. principled until it comes to their money.',\n",
              " '@user because she knew how to add up the millions in @user donations received for access?',\n",
              " '@user those idiots are fringe right. they are hated by most conservatives.',\n",
              " '@user @user @user i thought conservatives were the ones trying to rewrite history? thinking face url',\n",
              " '@user @user @user i linked to an article showing you why you are wrong. you are telling libertarians and conservatives\" aka the right what they supposedly believe. i am not bigoted, it is just a pattern i have noticed that never seems to be wrong.\"',\n",
              " '@user gritting her teeth, the blonde then broke her shield and feeling pumped the blonde charged after him. give me all you got!\" she then tossed some of her darts, aiming for his legs and would because only minor pain. \"show me how tough you are!\"\"',\n",
              " '@user the term parasite\" has now been added to my list of \"fuck you\" terms, which also includes the term \"widget\".\"',\n",
              " '@user @user @user @user @user i just spoke with antifa and blm. they said you lied.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gMm0A0E_8yP",
        "colab_type": "text"
      },
      "source": [
        "### Albert preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txpyrhPY3oHm",
        "colab_type": "code",
        "outputId": "25d37ede-eb63-43ff-eb72-96d2fce0813c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "! pip install bert-for-tf2\n",
        "! pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/b4/1a3da73498960866ad0510ead86b133569ff012bf1c77d82ce95203779fc/bert-for-tf2-0.13.2.tar.gz (40kB)\n",
            "\r\u001b[K     |████████▏                       | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 2.5MB/s \n",
            "\u001b[?25hCollecting py-params>=0.7.3\n",
            "  Downloading https://files.pythonhosted.org/packages/ec/17/71c5f3c0ab511de96059358bcc5e00891a804cd4049021e5fa80540f201a/py-params-0.8.2.tar.gz\n",
            "Collecting params-flow>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/12/2604f88932f285a473015a5adabf08496d88dad0f9c1228fab1547ccc9b5/params-flow-0.7.4.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.7.1->bert-for-tf2) (1.17.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.7.1->bert-for-tf2) (4.28.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.13.2-cp36-none-any.whl size=29938 sha256=33cc1f72d39464c89b3e3e94f31f8ed8a76b636c690e152ba97e0b7ce0cacdf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/e1/95/7fa0b466d35f4280a8842a6653f9cd37f89e83832770daf85f\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.8.2-cp36-none-any.whl size=4633 sha256=ca4c5f940c7f5db32f31a46a9f5e1615814c415afc922d79c9712280e05fe9e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/3a/9c/baf35d6f17f0c2c6b61bf8ac3ab9fc12df0e41432ccaeecacb\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.7.4-cp36-none-any.whl size=16196 sha256=3e6612e62d538a2ebd2073a311047f88b5807758d64007f6e1d0c9aca89c2ebc\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/30/40/507b60d68b67ac87f35e95c98f5b296a32f146d5ae1d1d5aa7\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.13.2 params-flow-0.7.4 py-params-0.8.2\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieMD2aSh9BAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "import sentencepiece as spm\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLCkf20VFOko",
        "colab_type": "code",
        "outputId": "ae927072-742a-4a02-efcc-a125cc45d2e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/albert_zh/albert_base_zh.zip\n",
        "!unzip albert_base_zh.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-04 19:09:01--  https://storage.googleapis.com/albert_zh/albert_base_zh.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42696199 (41M) [application/zip]\n",
            "Saving to: ‘albert_base_zh.zip’\n",
            "\n",
            "albert_base_zh.zip  100%[===================>]  40.72M  89.9MB/s    in 0.5s    \n",
            "\n",
            "2020-01-04 19:09:02 (89.9 MB/s) - ‘albert_base_zh.zip’ saved [42696199/42696199]\n",
            "\n",
            "Archive:  albert_base_zh.zip\n",
            "  inflating: albert_config_base.json  \n",
            "  inflating: albert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: albert_model.ckpt.index  \n",
            "  inflating: albert_model.ckpt.meta  \n",
            "  inflating: checkpoint              \n",
            "  inflating: vocab.txt               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8Is4Kv-o0Gd",
        "colab_type": "code",
        "outputId": "bebd486a-323e-416f-bf12-3dd81065c84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "model_name = \"albert_base\"\n",
        "model_dir    = bert.fetch_tfhub_albert_model(model_name, \".models\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\ralbert_base.tar.gz: 0.00B [00:00, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fetching ALBERT model: albert_base version: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "albert_base.tar.gz: 44.6MB [00:01, 43.4MB/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting to: .models/albert_base\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scnyfq63BZlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_segments(tokens, max_seq_length):\n",
        "#     if len(tokens)>max_seq_length:\n",
        "#       tokens = tokens[:max_seq_length]\n",
        "#       segments = []\n",
        "#       current_segment_id = 0\n",
        "#       for token in tokens:\n",
        "#         segments.append(current_segment_id)\n",
        "#         if token == \"[SEP]\":\n",
        "#           current_segment_id = 1\n",
        "#       return segments\n",
        "#     else:\n",
        "#       segments = []\n",
        "#       current_segment_id = 0\n",
        "#       for token in tokens:\n",
        "#         segments.append(current_segment_id)\n",
        "#         if token == \"[SEP]\":\n",
        "#           current_segment_id = 1\n",
        "#       return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "def preprocess_albert(sentence, sp, max_seq_length=128, do_lower_case=True):\n",
        "    tokens = bert.albert_tokenization.preprocess_text(sentence, lower=do_lower_case)\n",
        "    token_ids = bert.albert_tokenization.encode_ids(sp, tokens)\n",
        "\n",
        "    if len(token_ids) > max_seq_length:\n",
        "        return np.array(token_ids[:max_seq_length]) #, np.array([1] * max_seq_length)\n",
        "    else:\n",
        "        tokens_ids = token_ids + [0] * (max_seq_length - len(token_ids))\n",
        "        return np.array(tokens_ids) #, np.array([1] * len(tokens_ids) + [0] * (max_seq_length - len(tokens_ids)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7NWP4Ds8v0t",
        "colab_type": "code",
        "outputId": "fcc34506-d1a8-42e4-9135-796be415899a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spm_model = os.path.join(model_dir, \"assets\", \"30k-clean.model\") \n",
        "sp = spm.SentencePieceProcessor() \n",
        "sp.load(spm_model) \n",
        "\n",
        "X_train = np.array([preprocess_albert(sentence, sp) for sentence in training_x]) #.transpose(1, 0, 2)\n",
        "X_valid = np.array([preprocess_albert(sentence, sp) for sentence in validation_x]) #.transpose(1, 0, 2)\n",
        "X_test = np.array([preprocess_albert(sentence, sp) for sentence in test_x]) #.transpose(1, 0, 2)\n",
        "\n",
        "X_train.shape, X_valid.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11916, 128), (1324, 128), (860, 128))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obw1XWLqAB5k",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTKws4kPVR1k",
        "colab_type": "code",
        "outputId": "6410e7de-caa9-407b-b7ff-bec50b72e1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from bert.loader import (StockBertConfig, map_stock_config_to_params)\n",
        "\n",
        "albert_config_file = \"albert_config_base.json\"\n",
        "\n",
        "# Read bert_layer parameters from config_file\n",
        "with open(albert_config_file, 'r') as reader:\n",
        "    albert_config = StockBertConfig.from_json_string(reader.read())\n",
        "    albert_params = map_stock_config_to_params(albert_config)\n",
        "    # \"vocab_size\": 21128,\n",
        "    albert_params['vocab_size'] = 30000\n",
        "    albert_params['use_token_type'] = False\n",
        "    print(albert_params)\n",
        "    albert_params.adapter_size = None  # for now\n",
        "    albert_layer = bert.BertModelLayer.from_params(albert_params, name=\"albert\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'trainable': True, 'name': None, 'dtype': 'float32', 'dynamic': False, 'initializer_range': 0.02, 'max_position_embeddings': 512, 'hidden_size': 768, 'embedding_size': 128, 'project_embeddings_with_bias': True, 'vocab_size': 30000, 'use_token_type': False, 'use_position_embeddings': True, 'token_type_vocab_size': 2, 'hidden_dropout': 0.0, 'extra_tokens_vocab_size': None, 'project_position_embeddings': True, 'mask_zero': False, 'adapter_size': None, 'adapter_activation': 'gelu', 'adapter_init_scale': 0.001, 'num_heads': 12, 'size_per_head': None, 'query_activation': None, 'key_activation': None, 'value_activation': None, 'attention_dropout': 0.0, 'negative_infinity': -10000.0, 'intermediate_size': 3072, 'intermediate_activation': 'gelu', 'num_layers': 12, 'out_layer_ndxs': None, 'shared_layer': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epkaE0fRH5FP",
        "colab_type": "code",
        "outputId": "8c3ad980-3e80-4170-a610-33ee4f75624e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "albert_layer.get_config()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adapter_activation': 'gelu',\n",
              " 'adapter_init_scale': 0.001,\n",
              " 'adapter_size': None,\n",
              " 'attention_dropout': 0.0,\n",
              " 'dtype': 'float32',\n",
              " 'dynamic': False,\n",
              " 'embedding_size': 128,\n",
              " 'extra_tokens_vocab_size': None,\n",
              " 'hidden_dropout': 0.0,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_activation': 'gelu',\n",
              " 'intermediate_size': 3072,\n",
              " 'key_activation': None,\n",
              " 'mask_zero': False,\n",
              " 'max_position_embeddings': 512,\n",
              " 'name': 'albert',\n",
              " 'negative_infinity': -10000.0,\n",
              " 'num_heads': 12,\n",
              " 'num_layers': 12,\n",
              " 'out_layer_ndxs': None,\n",
              " 'project_embeddings_with_bias': True,\n",
              " 'project_position_embeddings': True,\n",
              " 'query_activation': None,\n",
              " 'shared_layer': True,\n",
              " 'size_per_head': None,\n",
              " 'token_type_vocab_size': 2,\n",
              " 'trainable': True,\n",
              " 'use_position_embeddings': True,\n",
              " 'use_token_type': False,\n",
              " 'value_activation': None,\n",
              " 'vocab_size': 30000}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAv7GjdzcAVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# def flatten_layers(root_layer):\n",
        "#     if isinstance(root_layer, keras.layers.Layer):\n",
        "#         yield root_layer\n",
        "#     for layer in root_layer._layers:\n",
        "#         yield from flatten_layers(layer)\n",
        "\n",
        "def flatten_layers(root_layer):\n",
        "    if isinstance(root_layer, keras.layers.Layer):\n",
        "        yield root_layer\n",
        "    for layer in root_layer._layers:\n",
        "        for sub_layer in flatten_layers(layer):\n",
        "            yield sub_layer\n",
        "\n",
        "\n",
        "def freeze_layers(root_layer):\n",
        "    \"\"\"\n",
        "    Freezes all but LayerNorm and adapter layers - see arXiv:1902.00751.\n",
        "    \"\"\"\n",
        "    for layer in flatten_layers(root_layer):\n",
        "        if layer.name in [\"LayerNorm\", \"adapter-down\", \"adapter-up\"]:\n",
        "            layer.trainable = True\n",
        "        elif len(layer._layers) == 0:\n",
        "            layer.trainable = False\n",
        "        root_layer.embeddings_layer.trainable = False\n",
        "\n",
        "# def freeze_layers(root_layer, exclude=None):\n",
        "#     exclude = [] if exclude is None else exclude\n",
        "#     root_layer.trainable = False\n",
        "#     for layer in flatten_layers(root_layer):\n",
        "#         print(layer.name, layer.trainable)\n",
        "#         if layer.name in exclude:\n",
        "#             layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg6qXC9gUuHi",
        "colab_type": "code",
        "outputId": "9517db0a-727a-40a0-8682-1dadb8fa81b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "max_seq_len = 128\n",
        "\n",
        "input_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
        "\n",
        "# input_mask = tf.keras.layers.Input(shape=(max_seq_len,), dtype='int32',\n",
        "#                                    name=\"input_mask\")\n",
        "# segment_ids = tf.keras.layers.Input(shape=(max_seq_len,), dtype='int32',\n",
        "#                                     name=\"segment_ids\")\n",
        "\n",
        "# NOTE: Following line not required if using default token_type/segment id 0\n",
        "# token_type_ids = keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
        "output = albert_layer(input_ids)  # output:[batch_size, MAX_SEQ_LEN, hidden_size]\n",
        "# NOTE: The following is an alternative for classification taken from\n",
        "# https://github.com/kpe/bert-for-tf2/blob/master/examples/gpu_movie_reviews.ipynb\n",
        "# The Lambda layer just takes one output from the sequence\n",
        "cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(output)\n",
        "# TODO: Try with more regularisation\n",
        "# cls_out = keras.layers.Dropout(rate=0.5)(cls_out)\n",
        "logits = keras.layers.Dense(units=256, activation='relu')(cls_out)\n",
        "logits = keras.layers.Dropout(rate=0.2)(logits)\n",
        "# NOTE: Alternative to the Lambda layer\n",
        "# bgru_layer = keras.layers.Bidirectional(keras.layers.GRU(64))(output)\n",
        "output = keras.layers.Dense(units=1, activation='sigmoid')(logits)\n",
        "model = keras.Model(inputs=input_ids, outputs=output)\n",
        "\n",
        "# Freeze all non-trainable layers\n",
        "freeze_layers(albert_layer)\n",
        "# Originally from tutorial: ['LayerNorm', 'adapter-down', 'adapter-up']\n",
        "\n",
        "# Build model and load pre-trained weights\n",
        "model.build(input_shape=(None, max_seq_len))\n",
        "bert.load_albert_weights(albert_layer, model_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done loading 22 BERT weights from: .models/albert_base into <bert.model.BertModelLayer object at 0x7f2df3e35a20> (prefix:albert_4). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
            "Unused weights from saved model: \n",
            "\tbert/embeddings/token_type_embeddings\n",
            "\tbert/pooler/dense/bias\n",
            "\tbert/pooler/dense/kernel\n",
            "\tcls/predictions/output_bias\n",
            "\tcls/predictions/transform/LayerNorm/beta\n",
            "\tcls/predictions/transform/LayerNorm/gamma\n",
            "\tcls/predictions/transform/dense/bias\n",
            "\tcls/predictions/transform/dense/kernel\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeJ6cvz5uZDU",
        "colab_type": "code",
        "outputId": "cd42d663-0f76-4ddc-980b-e7de042600d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    loss=weighted_bce,\n",
        "    optimizer=Adam(lr=1e-5),\n",
        "    metrics=[precision_m, recall_m, f1_m],\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 128)]             0         \n",
            "_________________________________________________________________\n",
            "albert (BertModelLayer)      (None, 128, 768)          11092736  \n",
            "_________________________________________________________________\n",
            "lambda_7 (Lambda)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               196864    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 11,289,857\n",
            "Trainable params: 197,121\n",
            "Non-trainable params: 11,092,736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piMdSTUzVd0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sle1HTD8RTJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_learning_rate_scheduler(max_learn_rate=5e-5,\n",
        "                                   end_learn_rate=1e-7,\n",
        "                                   warmup_epoch_count=10,\n",
        "                                   total_epoch_count=90):\n",
        "\n",
        "    def lr_scheduler(epoch):\n",
        "        if epoch < warmup_epoch_count:\n",
        "            res = (max_learn_rate/warmup_epoch_count) * (epoch + 1)\n",
        "        else:\n",
        "            res = max_learn_rate*math.exp(math.log(end_learn_rate/max_learn_rate)*(epoch-warmup_epoch_count+1)/(total_epoch_count-warmup_epoch_count+1))\n",
        "        return float(res)\n",
        "    learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "\n",
        "    return learning_rate_scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6jEx_37VQen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_epoch_count = 20\n",
        "\n",
        "callbacks = [create_learning_rate_scheduler(max_learn_rate=1e-5,\n",
        "                                            end_learn_rate=1e-7,\n",
        "                                            warmup_epoch_count=20,\n",
        "                                            total_epoch_count=total_epoch_count),\n",
        "                     keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHVhh_SNtlmY",
        "colab_type": "code",
        "outputId": "1e229299-eabe-43b4-86ff-92c385b5fc88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "source": [
        "history = model.fit(x=X_train, y=training_y,\n",
        "                    batch_size=48,\n",
        "                    # shuffle=True,\n",
        "                    epochs=20,\n",
        "                    validation_data=(X_valid, validation_y))\n",
        "\n",
        "model.save_weights('final_albert.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11916 samples, validate on 1324 samples\n",
            "Epoch 1/20\n",
            "11916/11916 [==============================] - 72s 6ms/sample - loss: 0.8773 - precision_m: 0.2494 - recall_m: 0.0832 - f1_m: 0.1188 - val_loss: 0.7173 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 2/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7551 - precision_m: 0.3565 - recall_m: 0.1184 - f1_m: 0.1695 - val_loss: 0.7166 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 3/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7557 - precision_m: 0.3180 - recall_m: 0.0952 - f1_m: 0.1388 - val_loss: 0.7175 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 4/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7448 - precision_m: 0.3329 - recall_m: 0.0824 - f1_m: 0.1248 - val_loss: 0.7187 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 5/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7373 - precision_m: 0.3263 - recall_m: 0.0675 - f1_m: 0.1058 - val_loss: 0.7172 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 6/20\n",
            "11916/11916 [==============================] - 70s 6ms/sample - loss: 0.7330 - precision_m: 0.2947 - recall_m: 0.0469 - f1_m: 0.0773 - val_loss: 0.7175 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 7/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7318 - precision_m: 0.2712 - recall_m: 0.0365 - f1_m: 0.0615 - val_loss: 0.7176 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 8/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7307 - precision_m: 0.1986 - recall_m: 0.0231 - f1_m: 0.0395 - val_loss: 0.7177 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 9/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7282 - precision_m: 0.1562 - recall_m: 0.0145 - f1_m: 0.0260 - val_loss: 0.7182 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 10/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7258 - precision_m: 0.0716 - recall_m: 0.0059 - f1_m: 0.0108 - val_loss: 0.7194 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 11/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7219 - precision_m: 0.0663 - recall_m: 0.0051 - f1_m: 0.0093 - val_loss: 0.7186 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 12/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7227 - precision_m: 0.0241 - recall_m: 0.0018 - f1_m: 0.0033 - val_loss: 0.7188 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 13/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7217 - precision_m: 0.0080 - recall_m: 4.1218e-04 - f1_m: 7.8409e-04 - val_loss: 0.7181 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 14/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7202 - precision_m: 0.0080 - recall_m: 4.3507e-04 - f1_m: 8.2329e-04 - val_loss: 0.7182 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 15/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7186 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.7198 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 16/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7185 - precision_m: 0.0040 - recall_m: 1.7461e-04 - f1_m: 3.3467e-04 - val_loss: 0.7207 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 17/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7185 - precision_m: 0.0040 - recall_m: 2.5100e-04 - f1_m: 4.7248e-04 - val_loss: 0.7194 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 18/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7177 - precision_m: 0.0040 - recall_m: 3.0893e-04 - f1_m: 5.7372e-04 - val_loss: 0.7184 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 19/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7179 - precision_m: 0.0040 - recall_m: 2.6774e-04 - f1_m: 5.0201e-04 - val_loss: 0.7188 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 20/20\n",
            "11916/11916 [==============================] - 69s 6ms/sample - loss: 0.7173 - precision_m: 0.0040 - recall_m: 2.6774e-04 - f1_m: 5.0201e-04 - val_loss: 0.7189 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKYKWS-do-4k",
        "colab_type": "text"
      },
      "source": [
        "## Albert using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih57UwrTpFVV",
        "colab_type": "code",
        "outputId": "4b11433d-6ca9-487d-94fd-62ba6b14e8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip install simpletransformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simpletransformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/cd/73ec93aa0ddefc75a963928d8b670e0ddbbb97456479fe3f10eb71f11d82/simpletransformers-0.18.2-py3-none-any.whl (98kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (0.22.1)\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/f8/87d46d306cad42e3a421471a6e8fd8728c731491f5e61c8f15bb5b3dcd36/wandb-0.8.20-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.17.5)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2019.12.20)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2.21.0)\n",
            "Collecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->simpletransformers) (0.14.1)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/0b/ba1655f0e9c248538b02322a979b5cd485156f5cc16ea34a3cff563527ee/sentry_sdk-0.14.0-py2.py3-none-any.whl (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 7.7MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.5MB/s \n",
            "\u001b[?25hCollecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (1.12.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (5.4.8)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (7.352.0)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e3/5a55d48a29300160779f0a0d2776d17c1b762a2039b36de528b093b87d5b/watchdog-0.9.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.3MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/2a/95ed0501cf5d8709490b1d3a3f9b5cf340da6c433f896bbe9ce08dbe6785/configparser-4.0.2-py2.py3-none-any.whl\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/80/d7/2bfc9332e68d3e15ea97b9b1588b3899ad565120253d3fd71c8f7f13b4fe/shortuuid-0.5.0.tar.gz\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/8c/4543981439d23c4ff65b2e62dddd767ebc84a8e664a9b67e840d1e2730d3/GitPython-3.0.5-py3-none-any.whl (455kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (2.6.1)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (7.0)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->simpletransformers) (2.2.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers->simpletransformers) (0.1.85)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers->simpletransformers) (1.10.47)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2.8)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers) (3.10.0)\n",
            "Collecting graphql-core<2,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb->simpletransformers) (2.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb->simpletransformers) (3.13)\n",
            "Collecting argh>=0.24.1\n",
            "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting gitdb2>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.1.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers->simpletransformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers->simpletransformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers->simpletransformers) (0.9.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers) (42.0.2)\n",
            "Collecting smmap2>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers->simpletransformers) (0.15.2)\n",
            "Building wheels for collected packages: seqeval, subprocess32, gql, watchdog, shortuuid, sacremoses, graphql-core, pathtools\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=0b7cd861eab908319ef761379f0adf3f40212f80c2c2bce7be328f02f7f40f61\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=0ddb06a71462d920e566723ced003c650e4614188ab73e041afa733768349440\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=38d245b243012e5697fa54f2031179dc8d8d7f418335906b7d3e8eef01152d50\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.9.0-cp36-none-any.whl size=73652 sha256=e377d625c2162c362cea69c051f5158bac83b1d9b79ac8b21247963270623ae0\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1d/d0/04cfe495619be2095eb8d89a31c42adb4e42b76495bc8f784c\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shortuuid: filename=shortuuid-0.5.0-cp36-none-any.whl size=5499 sha256=108bd092ac26b8bd269556c5ad0efb6199bbc2784b0e2a5010ea9232fdc22218\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/eb/fd/69e5177f67b505e44acbd1aedfbe44b91768ee0c4cd5636576\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=cee726c4c23bfcb7ea0f6de09dcd730be7cde6aa7744b258cb63d82fea6c429b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104651 sha256=159aea1053022ee1bcf32fd1943f8017a9f46f580d24020ce65f15829412daa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8786 sha256=24bec3512ef841c42e843c38be248e526b0bca77b9ed4c9705febac5778fe102\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built seqeval subprocess32 gql watchdog shortuuid sacremoses graphql-core pathtools\n",
            "Installing collected packages: sentry-sdk, docker-pycreds, subprocess32, graphql-core, gql, argh, pathtools, watchdog, configparser, shortuuid, smmap2, gitdb2, GitPython, wandb, seqeval, sacremoses, transformers, tensorboardx, simpletransformers\n",
            "Successfully installed GitPython-3.0.5 argh-0.26.2 configparser-4.0.2 docker-pycreds-0.4.0 gitdb2-2.0.6 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sacremoses-0.0.38 sentry-sdk-0.14.0 seqeval-0.0.12 shortuuid-0.5.0 simpletransformers-0.18.2 smmap2-2.0.5 subprocess32-3.5.4 tensorboardx-2.0 transformers-2.3.0 wandb-0.8.20 watchdog-0.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "configparser"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iricyWdrqPO",
        "colab_type": "code",
        "outputId": "33274889-5257-4925-adf4-8bfd944d8016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! git clone https://github.com/NVIDIA/apex\n",
        "! pip install -v --no-cache-dir ./apex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 5632 (delta 20), reused 23 (delta 10), pack-reused 5585\u001b[K\n",
            "Receiving objects: 100% (5632/5632), 13.37 MiB | 22.12 MiB/s, done.\n",
            "Resolving deltas: 100% (3641/3641), done.\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-d7sh1kpb\n",
            "Created temporary directory: /tmp/pip-req-tracker-uiookh3m\n",
            "Created requirements tracker '/tmp/pip-req-tracker-uiookh3m'\n",
            "Created temporary directory: /tmp/pip-install-jycmyx0k\n",
            "Processing ./apex\n",
            "  Created temporary directory: /tmp/pip-req-build-b5hkum2h\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-uiookh3m'\n",
            "    Running setup.py (path:/tmp/pip-req-build-b5hkum2h/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "    torch.__version__  =  1.3.1\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-b5hkum2h/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-b5hkum2h/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-b5hkum2h/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-b5hkum2h/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-b5hkum2h/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-b5hkum2h/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-b5hkum2h/setup.py:43: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-b5hkum2h has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-uiookh3m'\n",
            "Building wheels for collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-wheel-g7j7sltn\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-g7j7sltn\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-b5hkum2h/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-b5hkum2h/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-g7j7sltn --python-tag cp36\n",
            "  torch.__version__  =  1.3.1\n",
            "  /tmp/pip-req-build-b5hkum2h/setup.py:43: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/apex\n",
            "  copying apex/__init__.py -> build/lib/apex\n",
            "  creating build/lib/apex/pyprof\n",
            "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
            "  creating build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
            "  creating build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  creating build/lib/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "  creating build/lib/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "  creating build/lib/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "  creating build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "  creating build/lib/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "  creating build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "  creating build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "  creating build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
            "  creating build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
            "  creating build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
            "  creating build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "  creating build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "  creating build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  creating build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-g7j7sltn/apex-0.1-cp36-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'apex/__init__.py'\n",
            "  adding 'apex/RNN/RNNBackend.py'\n",
            "  adding 'apex/RNN/__init__.py'\n",
            "  adding 'apex/RNN/cells.py'\n",
            "  adding 'apex/RNN/models.py'\n",
            "  adding 'apex/amp/__init__.py'\n",
            "  adding 'apex/amp/__version__.py'\n",
            "  adding 'apex/amp/_amp_state.py'\n",
            "  adding 'apex/amp/_initialize.py'\n",
            "  adding 'apex/amp/_process_optimizer.py'\n",
            "  adding 'apex/amp/amp.py'\n",
            "  adding 'apex/amp/compat.py'\n",
            "  adding 'apex/amp/frontend.py'\n",
            "  adding 'apex/amp/handle.py'\n",
            "  adding 'apex/amp/opt.py'\n",
            "  adding 'apex/amp/rnn_compat.py'\n",
            "  adding 'apex/amp/scaler.py'\n",
            "  adding 'apex/amp/utils.py'\n",
            "  adding 'apex/amp/wrap.py'\n",
            "  adding 'apex/amp/lists/__init__.py'\n",
            "  adding 'apex/amp/lists/functional_overrides.py'\n",
            "  adding 'apex/amp/lists/tensor_overrides.py'\n",
            "  adding 'apex/amp/lists/torch_overrides.py'\n",
            "  adding 'apex/contrib/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
            "  adding 'apex/contrib/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
            "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
            "  adding 'apex/contrib/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
            "  adding 'apex/fp16_utils/__init__.py'\n",
            "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "  adding 'apex/fp16_utils/fp16util.py'\n",
            "  adding 'apex/fp16_utils/loss_scaler.py'\n",
            "  adding 'apex/multi_tensor_apply/__init__.py'\n",
            "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "  adding 'apex/normalization/__init__.py'\n",
            "  adding 'apex/normalization/fused_layer_norm.py'\n",
            "  adding 'apex/optimizers/__init__.py'\n",
            "  adding 'apex/optimizers/fused_adam.py'\n",
            "  adding 'apex/optimizers/fused_lamb.py'\n",
            "  adding 'apex/optimizers/fused_novograd.py'\n",
            "  adding 'apex/optimizers/fused_sgd.py'\n",
            "  adding 'apex/parallel/LARC.py'\n",
            "  adding 'apex/parallel/__init__.py'\n",
            "  adding 'apex/parallel/distributed.py'\n",
            "  adding 'apex/parallel/multiproc.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "  adding 'apex/parallel/sync_batchnorm.py'\n",
            "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "  adding 'apex/pyprof/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
            "  adding 'apex/pyprof/parse/__init__.py'\n",
            "  adding 'apex/pyprof/parse/__main__.py'\n",
            "  adding 'apex/pyprof/parse/db.py'\n",
            "  adding 'apex/pyprof/parse/kernel.py'\n",
            "  adding 'apex/pyprof/parse/nvvp.py'\n",
            "  adding 'apex/pyprof/parse/parse.py'\n",
            "  adding 'apex/pyprof/prof/__init__.py'\n",
            "  adding 'apex/pyprof/prof/__main__.py'\n",
            "  adding 'apex/pyprof/prof/activation.py'\n",
            "  adding 'apex/pyprof/prof/base.py'\n",
            "  adding 'apex/pyprof/prof/blas.py'\n",
            "  adding 'apex/pyprof/prof/conv.py'\n",
            "  adding 'apex/pyprof/prof/convert.py'\n",
            "  adding 'apex/pyprof/prof/data.py'\n",
            "  adding 'apex/pyprof/prof/dropout.py'\n",
            "  adding 'apex/pyprof/prof/embedding.py'\n",
            "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
            "  adding 'apex/pyprof/prof/linear.py'\n",
            "  adding 'apex/pyprof/prof/loss.py'\n",
            "  adding 'apex/pyprof/prof/misc.py'\n",
            "  adding 'apex/pyprof/prof/normalization.py'\n",
            "  adding 'apex/pyprof/prof/optim.py'\n",
            "  adding 'apex/pyprof/prof/output.py'\n",
            "  adding 'apex/pyprof/prof/pointwise.py'\n",
            "  adding 'apex/pyprof/prof/pooling.py'\n",
            "  adding 'apex/pyprof/prof/prof.py'\n",
            "  adding 'apex/pyprof/prof/randomSample.py'\n",
            "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
            "  adding 'apex/pyprof/prof/reduction.py'\n",
            "  adding 'apex/pyprof/prof/softmax.py'\n",
            "  adding 'apex/pyprof/prof/usage.py'\n",
            "  adding 'apex/pyprof/prof/utility.py'\n",
            "  adding 'apex/reparameterization/__init__.py'\n",
            "  adding 'apex/reparameterization/reparameterization.py'\n",
            "  adding 'apex/reparameterization/weight_norm.py'\n",
            "  adding 'apex-0.1.dist-info/LICENSE'\n",
            "  adding 'apex-0.1.dist-info/METADATA'\n",
            "  adding 'apex-0.1.dist-info/WHEEL'\n",
            "  adding 'apex-0.1.dist-info/top_level.txt'\n",
            "  adding 'apex-0.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp36-none-any.whl size=139506 sha256=942d3bb48dededdaabc645d30bf837c8fb396e416854338f9b0b6788f19ef6c2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d7sh1kpb/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n",
            "  Removing source in /tmp/pip-req-build-b5hkum2h\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-uiookh3m'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4y6JFJLvi6J",
        "colab_type": "code",
        "outputId": "b9a0de2d-ce42-4759-e445-0c118f3edeb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train_df = pd.DataFrame([])\n",
        "\n",
        "for x, y in zip(preprocessed_train, training_y):\n",
        "    row_df = pd.DataFrame([[x, y]])\n",
        "    train_df = train_df.append(row_df)\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user @user we do know she belongs to th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user you are a lying corrupt traitor!!! nobod...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user typical liberals. principled until...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user because she knew how to add up the milli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user those idiots are fringe right. they are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  @user @user @user we do know she belongs to th...  1\n",
              "0  @user you are a lying corrupt traitor!!! nobod...  1\n",
              "0  @user @user typical liberals. principled until...  0\n",
              "0  @user because she knew how to add up the milli...  0\n",
              "0  @user those idiots are fringe right. they are ...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JZS3qhixA_v",
        "colab_type": "code",
        "outputId": "fbd8d6ef-7b19-4e69-806e-b3228eef47d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "eval_df = pd.DataFrame([])\n",
        "\n",
        "for x, y in zip(preprocessed_test, test_y):\n",
        "    row_df = pd.DataFrame([[x, y]])\n",
        "    eval_df = eval_df.append(row_df)\n",
        "\n",
        "eval_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>who is q wheres the server dump nike dec las f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>constitution day is revered by conservatives, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>foxnews nra maga potus trump 2nd amendment rnc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>watching boomer getting the news that she is s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no pasaran unity demo to oppose the far-right ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  who is q wheres the server dump nike dec las f...  1\n",
              "0  constitution day is revered by conservatives, ...  0\n",
              "0  foxnews nra maga potus trump 2nd amendment rnc...  0\n",
              "0  watching boomer getting the news that she is s...  0\n",
              "0  no pasaran unity demo to oppose the far-right ...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfM4UTEEvSkx",
        "colab_type": "code",
        "outputId": "a1828a68-8a66-4bd5-a6ea-4f153e6670f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916,
          "referenced_widgets": [
            "b65b96c3750e48b6ba03ce279c625f5f",
            "c5448e8f37514be4872b67ed43000610",
            "9e5a8bf25d594f35a231f56d3f864d4a",
            "9316c6ebd3984a068a1881702fb27a61",
            "76644df2201e430cb9829aaa7e6cb968",
            "4e12aae9fee9421d88e8f64fa7f1f893",
            "a83fafbd3c024812b48a2e06a47ddefa",
            "8abe820d394c455295790cfd17e789f0",
            "d973e8c8fdc7455b8a49c9dda6090d38",
            "e883f71b0a2242c882c61951457ae9b3",
            "fa223d4daa434277b9a9d86ad775955e",
            "a41882360f4e4f40b912f911e0e1e7bc",
            "938af0343b6b4ffaaa731b57b8869aff",
            "c7f6492fa6b545538dccfe5b9fc0b68e",
            "b3cbd2e78e294b4087578c213d8b0fcd",
            "f2ff90a100b04a0c93d04b27d7666ad6",
            "c6971012519040148f2c245238ce5535",
            "e96dd199b2a94df8a4171401ae685731",
            "8472b28ea9c84559a47d1ffefdca141d",
            "47766eeecd7a421aa5643a1b92e0b5c8",
            "e396a07924a94eb996a12afe67a90570",
            "42f4968c30fe445f8c274ca8a0535e7d",
            "7ce026d6033f456ebc1a36849f21beba",
            "c79ebf6839d74f06b343e2873db9c727",
            "9804a9836c464bffb1655cdfda45cc2d",
            "0773f29d5eb54f069098ecd518a60b81",
            "9a2c952321ec4820b0ffec329db6e025",
            "fe88dd88e96b42a3bb7610e1b69551c6",
            "f4b58730bc1640abba5c1cef39bdd8b3",
            "4b411b4800f14ccb8a508c37e8c860d0",
            "5ecdf92d63184133b3ab2c6194b4cc16",
            "4efd2779701d49698c47de9f34a0fc94",
            "7d13264a15ae495683e78c4da3fae69f",
            "2bf53c52c9c5440d9f4f870878fe4887",
            "248700e360294353ae3ddea51c18926b",
            "60517057ecd9458fb859ac0be3502ff6",
            "bc330254f4f44c5dbe18c6541cc3ada0",
            "758a8b752f294aa781ac9ebdc830ee1a",
            "7e2444d69d614343860eed442ee620b0",
            "25a23e86bcba4313b16db8a58663fd76",
            "d407fb23ef5c43eeaf4f3327fd3b1873",
            "3933afb769d0452781a49b5ee040bbc8",
            "033e2280b9f640fc8e40cd6346e38e20",
            "932844c55eef43c1a6628b434018536d",
            "85c24dda3fc44a1faa30d3240a25725b",
            "4d729771091c4eb785328c71451951d9",
            "45ec2ab8496649ecaa39eff3e8188698",
            "02c9fb1b93fb453883820de81cb3312e",
            "f5991b6a2e4940ae9c28334f5c22fc20",
            "4ccf7c059bc54eb0aa6ea57e41338134",
            "2c890bec13b940d3906472df4e952d5f",
            "b07a76b3dfa54db78d83f17b257c4829",
            "c00b8856b8c443aea032470ffe403662",
            "bc98cd6e7e2a45b6ab759819422d1bb0",
            "1ac8286998cf4553b064492b9f73a45a",
            "832a34a8483542abaab13572305cec98"
          ]
        }
      },
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "\n",
        "# Create a ClassificationModel\n",
        "\n",
        "model = ClassificationModel('albert', 'albert-base-v1', num_labels=2, weight=[0.49773756, 1.], args={'overwrite_output_dir': True})\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df, args={'num_train_epochs': 5})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting to features started. Cache is not used.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:183: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
            "  warnings.warn(\"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b65b96c3750e48b6ba03ce279c625f5f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=11916), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d973e8c8fdc7455b8a49c9dda6090d38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6971012519040148f2c245238ce5535",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Current iteration', max=1490, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rRunning loss: 0.707779"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:91: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running loss: 0.724835Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Running loss: 0.711126Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Running loss: 0.641250Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Running loss: 0.757540Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Running loss: 0.328692"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9804a9836c464bffb1655cdfda45cc2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Current iteration', max=1490, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Running loss: 0.596782Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "Running loss: 0.562511Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
            "Running loss: 0.565279Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
            "Running loss: 0.257480"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d13264a15ae495683e78c4da3fae69f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Current iteration', max=1490, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Running loss: 0.089388"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d407fb23ef5c43eeaf4f3327fd3b1873",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Current iteration', max=1490, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Running loss: 0.614120"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5991b6a2e4940ae9c28334f5c22fc20",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Current iteration', max=1490, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Running loss: 0.888022\n",
            "Training of albert model complete. Saved to outputs/.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmOkDwaFxLBB",
        "colab_type": "code",
        "outputId": "8ed08008-be07-4946-c4a2-c2dd2c70afe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "6aca32bf969b460bbb67860e569ac2e2",
            "4fdac0fc7e3348d1a0f8cf75619ac6ec",
            "29e6bee05196477a8dc41502c65fdf4a",
            "7b1457874dc5492c9d5bcd39581f0df3",
            "ba288174e3e747d189a65411449387de",
            "13a94b2aedfa4de2b4fae9f89810e646",
            "57e26a7d3af64bc58286e97a41acf3ee",
            "a3205006f67c4183894bbf54e3955cfd",
            "c105877e4d8343fda5163d8163a2391a",
            "6a9c5aa09a774cc69a73d1e29a0db612",
            "0f2db84ea5374618bb0677b1e6a79d1c",
            "5ea549101ae042b48ea4a8d00a231e39",
            "df63dcf6332d4dbe8818c9ae93cc1db6",
            "92ae2246f0794b90906f58ba7d1c0f79",
            "ee503e1c4878445db4a3ea8ea3596632",
            "1d1097fbfcc5473e94e62015619a456c"
          ]
        }
      },
      "source": [
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting to features started. Cache is not used.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:458: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
            "  warnings.warn(\"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6aca32bf969b460bbb67860e569ac2e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=860), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c105877e4d8343fda5163d8163a2391a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=108), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.4723160174778766,\n",
              " 'fn': 66,\n",
              " 'fp': 85,\n",
              " 'mcc': 0.574804541374808,\n",
              " 'tn': 535,\n",
              " 'tp': 174}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sOdxk6k1rQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision = result['tp'] / (result['fp'] + result['tp'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOCdLw4i2jUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recall = result['tp'] / (result['tp'] + result['fn'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLYRiJN43hhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1 = 2. * ((precision * recall) / (precision + recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmGP-oid3xkG",
        "colab_type": "code",
        "outputId": "12abc39d-7871-486c-b1e3-1c2df292e07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6718146718146718, 0.725, 0.6973947895791582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}